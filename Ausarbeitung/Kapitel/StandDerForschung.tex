\chapter{Stand der Forschung}

Die 3D Objekterkennung und Verfolgung kommt in vielen Anwendungsbereichen zum Einsatz. Daher wurden in den vergangenen Jahrzehnten viele Algorithmen bzw. Systeme dafür entwickelt, wie beispielsweise das kommerzielle Erkennungssystem von VICON \cite{VIC}. In diesem System werden acht Kameras benutzt, die das Zielobjekt bzw. die Person von verschiedenen Richtungen beobachten. Hierzu werden einige weiße Marken vorher am Ziel angebracht, damit dessen Positionen und Bewegungen von den Kameras gut erkannt werden können. Nach Vergleichen der Bilder von verschiedenen Kameras kann ein 3D Modell des Ziels in Echtzeit erzeugt werden. Das System findet im Bereich von Computerspielen und Filmindustrie sehr häufig Verwendung. Ein anderes Beispiel ist das neue Gerät ,,Kinect'' von Microsoft XBox360 \cite{KIN}. Eine 3D Kamera kann die 3D Bewegungsdaten von Spielern ansammeln, wodurch die Spieler das Spiel direkt mit ihren Körpern anstelle des traditionellen Kontrollers steuern können. Die Analyseverfahren der Objekterkennung basieren auf unterschiedlichen Charakteristika der Objekte und sind für verschiedenen Typen von Objekten geeignet. In der Arbeit von Lepetit und Fua sind die aktuellen Verfolgungsverfahren in zwei große Gruppen untergliedert worden: auf Marken basierte Objektverfolgungen und auf natürlichen Merkmale basierte Objektverfolgungen \cite{LF05}. Die Verfahren in der zweiten Gruppe können weiter in kantenbasiertes Verfahren, auf optischen Fluss basiertes Verfahren, Template basiertes Verfahren, Punktebasiertes Verfahren und das SLAM-Verfahren unterteilt werden. Im folgenden Abschnitt wird kurz auf die einzelnen Verfahren eingegangen.    

%In unserem System können alle Objekte in zwei Typen eingeteilt werden: die Objekte, die immer eine Seite zur Kamera richten, d.h. nur Bewegungen der Objekte in der Ebene von der Kamera beobachtet werden; und andere Objekte, die sich frei im Raum bewegen. Wir benennen den ersten Typ als feste Objekte z.B. der Arbeitsplatz, und den zweiten Typ als frei bewegte Objekte, z.B. das Werkzeug. Im Folgenden werden aktuelle Forschungsarbeiten über Objekterkennungsverfahren für beide Typen von Objekten erklären.


%\section{Feste Objekte}
%Das Problem für die Erkennung der festen Objekte kann als die Objekterkennung mit planaren Marken zusammengefasst werden. In diesem Bereich sind viele Systeme für die Erweiterte Realität implementiert worden. 

\section{Standardmarkenbasierte Verfahren}
Die Verfolgungsverfahren können in zwei Schritte unterteilt werden: Zuerst das Sammeln von Informationen über Bildsequenzen, um dann die Position des erkannten Objekts zu bestimmen. Die vordefinierten Marken können in beiden Schritten mehr Information liefern, wodurch die Objekte schneller und einfacher verfolgt werden können. Deshalb sind in diesem Bereich viele Systeme für die Erweiterte Realität implementiert worden. Ein Echtzeitsystem für Erweiterte Realität wurde von Zhang und Navab für Objektverfolgung in einer Industrieumgebung realisiert \cite{ZN00}. Sie haben eine Gruppe von vier Vierecken als eine Marke benutzt. Die Marke wird durch Farbe und weiße Flecken innerhalb der Vierecke kodiert. 
\\
\\
Ein anderes System heißt ARToolKit, und ist vom HITLab der Universität Washington entwickelt worden. Es ist eine bekannte Software-Bibliothek zur Entwicklung von Anwendungen für die Erweiterte Realität \cite{ART}. In ARToolKit wird ein Viereck mit schwarzer Umrandung als Marke benutzt. Das Muster in der Mitte kodiert die Marke und kann frei gewählt werden. Das Eingabebild wird zuerst in ein Binärbild umgewandelt und danach alle verbundenen schwarzen Pixel extrahiert. Die Figur innerhalb der schwarzen Umrandung wird segmentiert und mit dem früheren definierten Muster verglichen. Durch den Vergleich kann man das Projizieren zwischen dem Kamerakoordinatensystem und dem Musterkoordinatensystem bestimmen. 
\\
\\
ARToolKit liefert eine hohe Frame-Rate mit bis zu 30 fps bei niedrigem CPU-Bedarf. Eine dicke schwarze Umrandung garantiert die Stabilität des Systems, sodass die Marke in niedriger Auflösung sehr gut erkannt werden kann. Ein anderer wichtige Vorteil ist, dass die Verfolgung der ARToolKit keine Initialisierung benötigt. Dadurch wird nicht nur die Laufzeit am Anfang des Verfahrens gespart, sondern auch ein Chaos vermeiden, wenn die eingegebene Bildsequenz abgebrochen wird.   
%Wegen dieser Vorteile wird in unserem System ARToolKit benutzt werden, um die festen Objekte wie Arbeitsplätze zu erkennen.


%\section{Frei bewegte Objekte}
%Wegen der Bewegung in mehren Freiheitsgraden, ist die Erkennung der frei bewegten Objekte viele komplexer. Das System soll die komplette charakteristische Information des Objekts betrachten, um das gleiche Objekt wiederzuerkennen, wenn es noch mal unter die Kamera gebracht wird. Im wesentlichen beruhen die aktuellen Objekterkennungsverfahren auf Templates, Kanten und Punktes. 

\section{Verfahren basierend auf natürlichen Merkmalen}

\subsection{Kantenbasiertes Verfahren}
Das kantenbasierte Verfahren wurde in früheren Objektverfolgungssystemen häufig benutzt, weil es effizient und einfach zu realisieren ist \cite{LF05}. Die Hauptidee dieses Verfahrens liegt entweder darin, die Kanten des Objekts direkt von dem Bild herauszufinden und zu verfolgen, oder den Teil des Bildes mit starkem Gradient zu betrachten, damit man die Konturen des Objekts zum nächsten Zeitpunkt vorhersagen kann. RAPiD war eines der frühesten 3D Verfolgungsverfahren, das in Echtzeit laufen konnte \cite{H92}. Vacchetti und Lepetit haben ein neues, effizienteres Verfolgungsverfahren entwickelt, welches mehr als eine Voraussage für die ausgewählten Steuerpunkte darstellt \cite{VLF04}. Diese Erweiterung verstärkt die Stabilität der Verfolgung und erfüllt weiterhin die Echtzeitbedingung.   
%Falls ein Teil des Objekts von Händen oder anderem Werkzeug verdeckt wird, kann das Verfahren wegen des Verlustes der Kanteninformation keine richtige Lösungen liefern. Aus dem gleichen Grund entspricht das auf Punktwolke basiertes Objekterkennungsverfahren unseren Bedarf auch nicht. 

\subsection{Optischer Fluss basiertes Verfahren}
Der optische Fluss ist ein Vektorfeld, das die Bewegungsrichtung und die Bewegungsgeschwindigkeit für jeden Bildpunkt einer Bildsequenz bezeichnet. Die Berechnung des optischen Flusses kann als eine Differentialgleichung zusammengefasst werden, dessen Lösungsverfahren von Horn und Schunck entwickelt \cite{HS81} wurde. Black und     Yacoob benutzten ein auf reinen optischen Fluss basiertes Verfahren für die Verfolgung kleiner Veränderungen auf dem menschlichen Gesicht, um den Gesichtsausdruck zu bestimmen \cite{BY97}. Außerdem wurde ein Verfolgungssystem für den Innerstadtverkehr von Haag und Nagel durch die Verknüpfung der Information von optischem Fluss und den Kanten des Objekts implementiert \cite{HN99}.  


\subsection{Template basiertes Verfahren}
Im Template basierten Verfahren wird ein Objekt nicht durch lokale Merkmale, wie z.B. Kanten oder Punkte, sondern durch das globale Charakteristikum erkannt und verfolgt. Das Verfahren ist geeignet für komplexe Objekte, die nicht einfach durch lokale Merkmale bezeichnet werden können \cite{LF05}. Der Lucas-Kanade Algorithmus wurde anfänglich entwickelt, um den optischen Fluss zu berechnen \cite{LK81}, ist aber auch für die 2D Template basierte Verfolgung nutzbar. Jurie und Dhome haben einen Algorithmus für die Verfolgung von ebenen Objekten mithilfe von Hyperebenen entwickelt \cite{JD01}. In ihrer Arbeit wurde die Approximation der Abbildung des Objekts auf Hyperebenen abgeschätzt, wodurch die Translation des Objekts bestimmt werden kann. 
%Das templatebasierte Verfahren braucht eine relative große Menge der Samples für verschiedene Deformation des Templates für jedes Objekt. Da das ganze Template in der Verfolgungsphase mit den Samples verglichen werden soll, braucht das Verfahren viel Zeit. Obwohl das Verfahren für einige komplexe Objekte effektiv ist, ist es für unsere Situation aber nicht geeignet \cite{LF05}. 

\subsection{Punktebasiertes Verfahren}
Der Unterschied zwischen dem punktebasierten Verfahren und den oben beschriebenen Verfahren ist, dass nur lokale Merkmale betrachtet werden. Im Vergleich zum Verfahren, das globale Merkmale behandelt, ist das Verfolgungsverfahren mit lokalen Merkmalen viel stabiler, wenn es eine Kollision für mehrere Objekte gibt, oder die Messung der Merkmale stark gestört wird \cite{LF05}. Ein Verfahren wurde von Zhang et al. im Jahre 1995 realisiert, welches die nicht kalibrierten Bilder als Eingabe benutzen kann \cite{Z95}. In diesem Verfahren wird kein Modell der Epipolargeometrie verwendet, wodurch viele komplexe Berechnungen vermieden werden können. Eine andere Möglichkeit für die Punkteverfolgung ist der Kanade-Lucas-Tomasi (KLT) Tracker, welcher auf der Arbeit von \cite{LK81} begründet wurde. Sie haben eine Approximation für den Unterschied zwischen zwei Bildern definiert. Mithilfe des Iterationsverfahrens von Newton-Raphson wird die Approximation minimiert. Dadurch kann die Translation des Objekts bestimmt werden. Tomasi erweiterte den Algorithmus von Lucas und Kanade mit einer besseren Strategie zur Auswahl von Merkmalen \cite{TK91}. Der dritte Schritt wurde von Shi und Tomasi vervollständigt \cite{ST94}. Sie entwickelten die Auswahl der Punkte mit der Ähnlichkeit zwischen dem Anfangsbild und dem aktuelle Bild weiter. Diese Ähnlichkeit wird durch ein Modell von affinen Abbildungen bestimmt. Außerdem benutzen sie gleichzeitig ein zweites Modell mit einer reinen Translation, um das Objekt mit hoher Stabilität und Präzision zu verfolgen. 

\section{Markenbasierte Objekterkennung}
\label{MObjEr}
Rhijn und Mulder haben ein markenbasiertes Verfahren entwickelt, welches das Verdeckungsproblem behandelt \cite{AJ05}. Einige runde, hoch reflektierende Marken werden auf dem Objekt angebracht. In der Initialisierungsphase speichert das System die Charakteristika des Objekts als einen dreidimensionalen, vollständigen Graph. Wenn das Objekt wiedererkannt werden soll, führt das System zuerst einen Kalibrationsalgorithmus durch, um die verschiedenen Objekte zu differenzieren. Daraufhin vergleicht das System für jedes Objekt die sichtbaren Marken mit dem in der Initialisierungsphase gespeicherten vollständigen Graphen.  

\subsection{Markenerkennung}
\label{mErkennung}
Heutzutage gibt es viele benutzte Standardalgorithmen der Markenerkennung. Die Harris Matrix wird von der Summe der partiellen Ableitungen des Eingabebildes dargestellt. Dabei wird eine Ecke genau dann als ein Merkmal erkannt, wenn die beiden Eigenwerte der Harris-Matrix positiv und groß genug sind \cite{HS88}. Ein anderer Algorithmus für diese Eckenerkennung laute ,,Features from Accelerated Segment Test''(FAST) und wurde von Rosten und Drummond im Jahre 2006 veröffentlicht \cite{RD06}. Außer vorherigen Eckenerkennungsverfahren können sogar die Marken durch ähnliche Ideen erkannt werden. Das Ziel dieser Verfahrensart ist, die Punkte zu extrahieren, die unterschiedliche Eigenschaften zu ihrer Umgebung aufweisen, wie z.B Helligkeit und Farbe. Lowe hat seinen Algorithmus ,,Scale-invariant feature transform''(SIFT) im Jahre 2004 veröffentlicht, welcher eine starke Stabilität gegen Transformation, Beleuchtungsvariation bzw. Bildrauschen aufbringt \cite{L04}. Der Detektor arbeitet auf Basis einer Skalenraum-Analyse mit Difference of Gaussians (DoG), welches einer effiziente Approximation des skalen-normalisierten LoG-Operators (Laplacian of Gaussian) entspricht. Das lokale Extremum wird in DoG Bildern durch den Vergleich der direkten Nachbarn bzw. der Nachbarn aus nebeneinanderliegenden DoG Bildern gesucht. Der entsprechende Deskriptor wird als 128 dimensionaler Vektor definiert und besteht aus einem in Teil-Quadrate untergliederte Gradienten Histogramm. Bay et al. erweiterte die Arbeit von Lowe mit dem ,,Speeded Up Robust Feature''(SURF) \cite{B06}. Der Rechtecks-Filter wird in ihrer Arbeit anstelle eines DoGs verwendet, um den Detektionsablauf zu beschleunigen. Außerdem wird der Deskriptor auch um den Faktor 2 verkleinert, damit der Vergleich der zwei Merkmalsvektoren weniger Zeitintensiv ist. Der Algorithmus ,,Center Surround Extremas''(CenSurE oder STAR) benutzt einen sogenannten ,,Center-surround'' Filter, um den Laplace-Operator zu approximieren, damit die Betrachtung der Merkmale in allen Skalar-Räumen schnell durchgeführt werden kann \cite{AKB08}. Wegen diesen Veränderungen ist der CenSurE Algorithmus im Vergleich viel effizienter und stabiler. Die vorhandenen Realisierungen obiger Algorithmen können in der freien Programmbibliothek OpenCV gefunden werden. Anhand von OpenCV hat Odessa in seinem Blog die Geschwindigkeit, die Stabilität bzw. die Genauigkeit dieser Algorithmen verglichen \cite{O11}. Seinem Ergebnis zufolge scheint, der STAR Algorithmus die niedrigste durchschnittliche Fehler-Rate zu haben bzw. den geringsten Berechnungsaufwand zu benötigen.

%Die freie Programmbibliothek OpenCV liefert viele verschiedenen Algorithmen für Markenerkennung, und  werden von Odessa in seiner Ausarbeitung verglichen \cite{O11}. In diese Arbeit wird der Erkennungsalgorithmus STAR ausgewählt, wegen der niedrigen durchschnittlichen Fehler-Rate, was besonders wichtig für die Markenerkennung ist \cite{AKB08}. Außerdem betrachtet der STAR Algorithmus weniger Merkmale als andere Algorithmen, deshalb wird die gesamte Laufzeit der Markenerkennung verkürzt. Diese Eigenschaft entspricht genau unseren Anforderungen, weil nur wenige Marken an dem Objekt angebracht werden (weniger als 10 an jeder Oberfläche).

\subsection{Markenverfolgung}
Nach Bestimmung der Marken, sollen diese in einer Bildsequenz verfolgt werden. Scott und Longuet-Higgins haben einen eleganten und einfachen Algorithmus entwickelt und das Problem zu einer Matrix zusammengefasst, deren Elemente als die Distanz zwischen verschiedenen Merkmalen definiert werden \cite{SL91}. Durch eine Singulärwertzerlegung und Matrixersetzung werden die Abbildungen der Marken zwischen zwei Bildern bestimmt. Rhijn und Mulder verbesserten den Algorithmus von Scott und Longuet-Higgins, indem sie die Elemente der Matrix neu definiert und die Beschränkung der Epipolargeometrie eingefügt haben \cite{AJ05}.  

\subsection{Schätzung der Transformation}
Für ein 3D Objekt ist die Markenverfolgung innerhalb von Bildern nicht ausreichend, um die komplette geometrische Information zu rekonstruieren. Deshalb soll die Pose des Objekts gleichzeitig bestimmt werden, damit ein räumlicher charakteristischer Graph für das Objekt erstellt werden kann. Natürlich kann man mit Hilfe der Ergebnisse der Markenverfolgung die relative Rotation und Translation des Objekts zwischen zwei Zeitpunkten berechnen, aber außerdem gibt es Verfahren, die durch Vergleich der Punktwolken von zwei Bildern die Transformation des Objekts direkt bestimmen können. Diese Verfahren wurden von Eggert et al. in ihrer Arbeit durch Merkmale und Lösungsverfahren in verschiedene Typen unterteilt \cite{ELF97}. Hierbei können die Merkmale Oberflächen, Kanten oder Punkte sein. Die Verfahren, die auf Punkten basieren, werden in der Praxis häufig benutzt und sind für die markenbasierte Objekterkennung geeignet \cite{ELF97}. Bei den Lösungsverfahren kann zwischen iterativen Verfahren und geschlossene Formen unterschieden werden.

\subsubsection{Geschlossene Form}
Ein effizientes Verfahren mit geschlossener Form für das Berechnen der Transformation wurde von Arun et al. zuerst am Jahr 1987 veröffentlicht \cite{AHB87}. Die Hauptidee des Verfahrens ist, eine approximierte Rotations- bzw. Translationsmatrix zwischen zwei aufeinander folgenden Bildern zu bestimmen, um die Summe des Unterschieds zwischen den durch approximierte Transformation berechnete Positionen der Punkte und den genauen Positionen der Punkte zu minimieren. Dieses Verfahren basiert auf der Singulärwertzerlegung einer Korrelationsmatrix. Die Rotations- und Translationsmatrix werden am Ende ausgegeben. Wenn die zwei eingegebenen Punktwolken auf gleicher Oberfläche liegen, liefert das Verfahren leider keine richtige Rotationsmatrix. Deshalb soll eine korrigierte Matrix darauf aufbauen, welche von Umeyama \cite{U91} und Kanatani \cite{K94} vorgeschlagen wurde. Ein anderes Verfahren wurde von Horn entwickelt, welches die relative Rotation durch Einheitsquaternionen beschreibt \cite{H87}. Im Vergleich zu der Standard-Beschreibung der Rotation als Matrix ist die Quaternion-Darstellung viel effizienter und stabiler. Die verbesserte Stabilität kann den Fehler vermeiden, wenn der Winkel der Rotation zur Singularität wird, z.B. $0^\circ$ oder $180^\circ$. D.h. dieses Verfahren braucht keine Maßnahme für Behandlung des speziellen Winkels, das aber im Verfahren von Arun nötig ist \cite{AHB87}. 
\\
\\
Eggert et al. haben in ihrer Arbeit die obengenannten zwei Verfahren mit zwei anderen geschlossene Form-Verfahren verglichen \cite{ELF97}. Wenn die Anzahl der betrachteten Punkte weniger als 100 beträgt, braucht das Verfahren mit Einheitsquaternionen weniger Zeit als die anderen Verfahren. Auf der anderen Seite liefert das Verfahren von Arun den kleinsten Fehler, wenn die Anzahl der betrachteten Punkte weniger als 10 ist.

\subsubsection{Iterative Closest Point Algorithmus}
Der Iterative Closest Point Algorithmus (ICP) ist ein Algorithmus, der es ermöglicht, die Punktwolken aneinander anzupassen \cite{IW}. In jedem Iterationsschritt wird der korrespondierende Punkt für jeden Punkt einer Punktwolke aus einer anderen Punktwolke gefunden. Die Transformation zwischen beiden Punktwolken wird so bestimmt, dass die Summe des Abstands der korrespondierenden Punkte minimiert wird. Dieser Vorgang wird solang wiederholt, bis die Veränderung des mittleren quadratischen Fehlers zwischen zwei folgenden Schritten unter einem bestimmten Schwellenwert liegt. Der Algorithmus wurde zuerst von Chen und Medioni \cite{CM91} vorgestellt und unter dem Namen ICP erstmals in der Arbeit von Besl und McKay benutzt \cite{BM92}.  Doria et al. erweiterten den  Algorithmus mit einem gewichteten Kriterium für das Rauschen \cite{DMJ97}. Ein Vergleich der verschiedene ICP Algorithmen vor dem Jahr 2001 wurde von Rusinkiewicz und Levoy erstellt \cite{RL01}. Der grundlegende ICP Algorithmus wurde von ihnen in sechs Schritte unterteilt. In jedem Schritt wurde die Leistung des Algorithmus verglichen und ihr Einfluss auf den ganzen Algorithmus diskutiert. Eine andere Veränderung wurde von Chavarria und Sommer vorgeschlagen, in der die Kontur des Objekts auch in der Schätzung der Pose betrachtet wird \cite{CS07}.      

\subsection{Objektkalibrierung}
\subsubsection{Statistisches Verfahren}
Im Ablauf der markenbasierten Objekterkennung werden alle Objekte durch einige Marken alleine definiert. Deshalb kann für jedes Bild die Kalibrierung der Objekte als Clusteranalyse der Marken zusammengefasst werden. Josiger und Kirchner haben einen Vergleich über drei moderne Clusteralgorithmen erstellt \cite{JK03}. Diese lauften ,,Balanced Iterative Reducing and Clustering using Hierarchies''(BIRCH), ,,Density Based Spatial Clustering of Applications with Noise'' (DBSCAN) und CHAMELEON-Algorithmus. BIRCH-Algorithmus basiert auf dem Clustering-Feature-Tree, welcher einen balancierten Baum mit Verzweigungsfaktor und Schwelle als zusätzlichen Parameter darstellt \cite{Z96}. Ein vorhandener Clusteralgorithmus wird für die Blätter des Baums durchgeführt, damit die angeforderten Gruppen ausgesucht werden können. In CHAMELEON werden zuerst die Nachbarn des betrachteten Objekts bestimmt. Daraufhin wird die gesamte Menge der Daten durch die Ähnlichkeit in M Teile unterteilt, wobei M ein Eingabeparameter ist. Nach der Verschmelzung der M Teile werden die Daten schlussendlich in K Gruppen verteilt. Der Parameter K ist vordefiniert und zeigt die vom Benutzer gewünschte Anzahl der Gruppen \cite{K99}. Bei BIRCH oder CHAMELEON muss man die Anzahl der Cluster als Eingabe festliegen. Manchmal ist jedoch diese Zahl nicht bekannt oder schwer vorherzusagen. Der DBSCAN-Algorithmus, der von Ester et.al in Jahr 1996 veröffentlicht wurde, kann dieses Problem vermeiden \cite{E96}. Statt der gewünschten Anzahl der Cluster sollen ein Bereich $\epsilon$ und die Mindestanzahl der Nachbarn in diesem Bereich, die sogenannte Grenzdichte, vordefiniert werden. Das Objekt, das nicht genug Nachbarn im angeforderten Bereich aufweist, wird als Rauschen markiert. Die bleibenden Objekte werden im gleichen Cluster zusammengefasst, wenn sie nicht weiter als $\epsilon$ von mindesten N ihrer Nachbarn liegen, wobei N ein Eingabeparameter ist. In der Arbeit von Josiger und Kirchner werden die Ergebnisse der drei Algorithmen von verschiedenen Testdaten verglichen. Entweder für die Punktmenge in einfacher Gestalt oder für die Punktmenge in nicht-sphärischer Gestalt können die DBSCAN und CHAMELEON Algorithmen die zufriedenstellende Lösung liefern. In der Situation, in der die Testdaten verrauscht sind, kann der DBSCAN Algorithmus mit geeignetem Parameter auch ein zufriedenstellendes Ergebnis ausgeben. Das Ergebnis bleibt stabil, obwohl der Anteil des Rauschens stark ansteigt. 

\subsubsection{Dynamisches Verfahren}
Das Problem der Kalibrierung der Objekte ist ähnlich im Vergleich zum Problem der Segmentierung der Bewegungen in einer langen Bildsequenz. Eine traditionelle Lösungsstrategie ist, die Positionen der Marken im nächsten Zeitpunkt mit einem Kalman Filter vorherzusagen. Dann werden alle Marken anhand der kinematischen Parameter in verschiedene Gruppen eingeteilt. Mills und Novins haben eine andere Möglichkeit geliefert, um die Objekte direkt mit zweidimensionalen Graphen kalibrieren zu können \cite{MN00}. Am Anfang ihres Algorithmus wird jede Marke mit einander verbunden. Danach werden alle Marken und die dazwischenliegenden Kanten zusammen als ein vollständiger Graph dargestellt. Zwischen den Bewegungen der Objekte verändert sich die Länge der Kanten. Die Kanten, die länger als eingesetzte Beschränkung sind, werden aus dem Graphen schrittweise gelöscht. Eine Marke gehört genau dann zu einem Objekt, wenn das Dreieck, das von dieser Marke und anderen Marken in diesem Objekt erzeugt wird, mindestens eine gleiche Kante mit den anderen Dreiecken des Objekts hat. Am Ende des Algorithmus wird der ursprüngliche, vollständige Graph in viele Teilgraphen zerlegt, die genau den kalibrierten Objekten entsprechen. Es gibt jedoch die Einschränkung in dem Algorithmus von Mills und Novins, dass zwei Objekte nicht auseinanderzuhalten sind, wenn ihre Marken mit einigen besonderen Strukturen angebracht werden \cite{AJ05}. Rhijn und Mulder haben dieses Problem gelöst, indem sie die Voraussetzung des Algorithmus veränderten. In der neuen Voraussetzung darf die Marke nur dann in einem Objekt erkannt werden, wenn sie mit anderen drei Marken in dem Objekt zusammen eine Pyramide erzeugen kann. Hierbei bezieht sich die Pyramide auf einen Körper der Geometrie, der vier Knoten hat, von denen je zwei eine Kante erzeugen. Die neue stärkere Beschränkung erhöht die Erfolgsquote deutlich.

\subsection{Objekterkennung und Verfolgung} 
Das Ziel dieser Arbeit liegt darin, dass ein Objekt nach Initialisierung von dem System wieder erkannt werden kann. Eine Wiedererkennung des 3D Objekts durch 2D Bildfolgen wird von Lamdan et al. in ihrer Arbeit erfolgreich durchgeführt \cite{LSW88}. Sie haben einige interessante Punkte ausgewählt, um das totale Objekt zu beschreiben. Alle drei Punkte, die nicht auf einer gleichen Gerade liegen, definieren ein Koordinatensystem, auf dem die entsprechenden Koordinaten von anderen Punkten berechnet und in einem HashMap gespeichert werden. Die richtige Korrespondenz wird so bestimmt, dass das kleinste Quadrate-Modell der Transformation zwischen dem neuen Koordinatensystem und 2D-Bild die beste Lösung liefert.
\\
\\ 
Andererseits kann die charakteristische Information jedes Objekts einen einzigen vollständigen Graphen erzeugen. Alle sichtbaren Marken des erkannten Objektes können als ein Teilgraph des vollständigen Graphen definiert werden, wodurch das Problem der Objekterkennung bzw. Objektverfolgung als das sogenannte Teilgraph Isomorphismus Problem abgeleitet werden kann. Es gibt eine große Menge der Algorithmen, die das Problem behandeln, da das Isomorphismus Problem nicht nur im Bereich der Bildanalyse, sondern auch im Vergleich der Struktur von chemischen Verbindungen oder in biometrischer Identifikation häufig vorkommt. Conte et al. haben eine Zusammenfassung über diese Algorithmen veröffentlicht \cite{C04}. Durch ihre Taxonomie können sämtliche Verfahren in zwei Gruppen von genauen bzw. ungenauen Graph Matching Algorithmen unterteilt werden. 
\\
\\
In einem genauen Graph Matching wird die strenge Korrespondenz zwischen zwei Graphen bestimmt. Die Abbildung von einem Graphen zu einem anderen soll bijektiv sein. Ullmann hat ein rekursives Rücksetzverfahren beschrieben, das sehr bekannt ist und bis heute für ein genaues Matching häufig benutzt wird\cite{U76}. Was von Rhijn und Mulder in ihrer Arbeit für die Objekterkennung implementiert wurde, bezieht sich auch auf ein genaues Graph Matching Verfahren \cite{AJ05}. Sie folgen der Idee von Lamdan, aber verbessern das Verfahren mit einer Beschränkung für die Größe des Teilgraphs, die ausreichend für die Unterscheidung von zwei Objekten ist. Nach der Verbesserung ist der neue Algorithmus viel effizienter und stabiler. Cordella et al. haben einen Algorithmus mit Namen VF2 für das Graph und Teilgraph Isomorphismus Problem in großen Graphen entwickelt \cite{CF04}. In diesem Vorgang des Matching haben sie einige Regeln definiert, wodurch die Komplexität des Rechnens stark reduziert wird. Eppstein konzentriert auf das Teilgraph Isomorphismus Problem von planaren Graphen \cite{E99}, wobei der Graph in viele kleine Bäume unterteilt wird. Auf diesen wird dann mittels dynamischer Programmierung das Matching in linearer Zeit durchgeführt. 
\\
\\
Das genaue Graph Matching ist manchen Fällen ungeeignet, beispielsweise für nicht komplett fest definierte Graphen, das z.B. bei Rauschen oder instabilen Komponenten vorkommt. Wegen des Unterschieds zwischen dem beobachteten Modell und dem idealen Modell, soll das Matchingverfahren tolerant sein. Dadurch kann eine Korrespondenz zwischen zwei Graphen gefunden werden, obwohl es keine strenge Transformation dazwischen gibt. Außerdem benötigt das genaue Graph Matching Verfahren eine exponentielle Laufzeit im Worst-Case, die durch eine Approximation in ungenauen Matchingverfahren stark reduziert werden kann. Messmer und Bunke haben ein Fehler-tolerantes Verfahren für einen Teilgraph Isomorphismus mit unbekanntem Graph als Eingabe entwickelt \cite{MB98}. Die Modellgraphen werden durch eine Vorverarbeitung in kleine Teilgraphen unterteilt. Alle diese Teilgraphen werden so zusammengefasst, dass die öfter vorkommenden Teilgraphen nur einmal repräsentiert werden. Der eingegebene Graph wird mit diesen verdichteten Graphen verglichen, wodurch die Laufzeit nur von der Anzahl der Modellgraphen abhängt.



