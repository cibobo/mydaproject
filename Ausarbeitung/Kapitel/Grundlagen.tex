\chapter{Grundlagen}

\section{Generierung der 3D-Daten}

\subsection{TOF-Sensor}

\subsubsection{TOF Kamera}
\label{TOF Kamera}
Die im MAROCO-System verwendete Kamera gehört zur Klasse der TOF-Sensoren, die außer den normalen Graufarbenbildern auch Tiefbilder liefern kann. Die Tiefmessung basiert auf dem sogenannten Laufzeitverfahren. Dazu wird die Szene durch ein Lichtpuls ausgeleuchtet und für jeden Bildpunkt wird die Zeit gemessen, die das Licht bis zum Objekt und wieder zurück braucht. Die Distanz ist direkt proportional zu der benötigen Zeit und kann durch die folgende Formel berechnet werden:

\begin{equation}
\label{tof1}
d = \frac{t_d}{2c}
\end{equation} 

wobei $t_d$ die gemessene Zeit bezeichnet. Die Konstante $c$ steht für die Lichtgeschwindigkeit. 
\\
\\
Im Vergleich zu anderen 3D Kamerasystemen hat die TOF Kamera viele Vorteilen \cite{TOFWiki}. Zuerst kann die TOF Kamera einfach die interessierenden Bereiche aus einem Bild extrahieren und nur die Pixel nah vor der Kamera betrachten. Zweitens, kann die TOF Kamera eine hohe Bildrate bis zu 80 bps erreichen. Diese Eigenschaft ermöglicht somit Echtzeitanwendungen. Außerdem benötigt die TOF Kamera weniger Platz als z.B. das Triangulationssystem und hat niedrigere Abhängigkeit von der Systemstruktur gegenüber dem Stereosystem.


\subsubsection{PMD Sensor}
Der PMD Sensor heißt CamCube ist eine wichtige Komponente der TOF Kamera. Er liefert eine hohe Auflösung bis zum 204x204 Pixel und maximale Bildrate bis zum 40 bps. Durch Formel \eqref{tof1} wird der maximale Distanzbereich zum 7 m festgelegt. Die andere wichtigen Parameter findet man in Abbildung~\ref{PMDParam} \cite{pmde}.
\\
\\
%\graphicspath{}
\begin{figure}[ftb]
\centering
\includegraphics[scale=0.6]{Abbildungen/PMDParam}
\caption{Die grundlegende Parameter der PMD Kamera. \cite{pmde}}
\label{PMDParam}
\end{figure}

Das Hintergrundlicht, z.B. das Sonnenlicht, könnte die Messung der Distanz stark stören. Die PMD Kamera benutzt das aktive Sendersignal und einen Fremdlicht-Filter (SBI), um das Hintergrundsignal zu unterdrücken. Außerdem bietet die PMD Kamera die Möglichkeit, die Integrationszeit der Kamera für jede Messung individuell einzustellen. Die Integrationszeit bezieht sich auf die Zeitspanne, in der die Kamera zur Aufzeichnung eines Bildes dem reflektierten Licht ausgesetzt wird. Für ein schwach reflektierendes Objekt benötigt der Sensor längere Integrationszeit als ein stark reflektierendes Objekt, um genug Information anzusammeln. Andererseits wird aber ausreichendes Licht von hellen Objekten auf den Sensor reflektiert, wenn die Integrationszeit zu lang definiert wird. In Abbildung~\ref{PMDIntTime} wird ein Beispiel der Tiefbilder mit verschiedenen Integrationszeiten gezeigt \cite{pmdd}. 

\begin{figure}[ftb]
\centering
\includegraphics[scale=0.6]{Abbildungen/PMDIntTime}
\caption{Integrationszeit von 140 $\mu s$, 1400 $\mu s$ bzw. 14000 $\mu s$. Bitte beachten Sie die niedrige Signalstärke an der linken Seite und die Sättigung an der rechten Seite wegen der unangemessenen Integrationszeit. \cite{pmdd}}
\label{PMDIntTime}
\end{figure}

\subsubsection{Unterschied zwischen TOF Kamera und Kinect}
Kinect ist eine Hardware zur Steuerung der Videospielkonsole Xbox360, die ein sogenanntes hands-free Kontrollieren liefert, wodurch die Spieler mit einigen bestimmten Gesten oder einer kurzen Bewegung ihres Körpers das Spiel spielen können \cite{KIN}. Um dieses Ziel zu erreichen, sammelt Kinect außer der normalen Bildeingabe aber auch die Tiefdaten der Szene an. Wegen dieser Eigenschaft wird das Gerät im Bereich von Computer Vision benutzt. Mithilfe des SDK ist die Programmierung der Kinect unter normalen Betriebssystemen z.B. Windows, Linux bzw. MacOS möglich. 
\\

\begin{figure}[bft]
\centering
\includegraphics[scale=0.6]{Abbildungen/Kinect}
\caption{Das Arbeitsprinzip des Kinects. \cite{KINH}}
\label{Kinect}
\end{figure}

Der Unterschied zwischen TOF Kamera und Kinect können auf dem Arbeitsprinzip zurückgeführt werden. In TOF Kameras wird die Tiefdaten durch dem Laufzeitverfahren berechnet, was im \ref{TOF Kamera} erklärt wird. Das Abtastverfahren der Kinect heißt Light Coding. Eine große Menge von Streifen werden als Mustern auf die Szene bzw. die Objekte durch infrarotes Licht projiziert. Die ganz Szene mit diesen zusätzlichen Mustern wird von einer infraroten Kamera des Kinects aufgenommen. Durch die Verzerrung zwischen dem vordefinierten Muster im infraroten Licht und dem von der infraroten Kamera erkannten Muster kann das Tiefbild der Szene ausgerechnet werden. Die Abbildung~\ref{Kinect} zeigt dieses Arbeitsprinzip der Kinect. Die weitere Information findet man im technischen Dokument des Firma Cadet \cite{KINH}. Der Vergleich über die genauen technischen Daten von PMD Kamera und Kinect wird in Tabelle~\ref{PMD and Kinect} zusammengefasst. Obwohl Kinect eine bessere Auflösung und größeres Sichtfeld hat, ist die PMD Kamera wegen ihrer hohen Bildrate und großen Messbereich für das MAROCO-System geeignet. Außerdem mithilfe des SBI Systems ist die Arbeit der PMD Kamera unter schwieriger Umgebungsbedingung, z.B. außerhalb des Zimmers mit starker Störung von Sonneneinstrahlung, auch möglich.

\begin{table}[ftb]
\begin{center}
\begin{tabular}{| l || c | c |}
\hline
Sensor & PMD CamCube & Kinect \\ \hline
Auflösung & 204$\times$204 Pixel & 640$\times$480 Pixel\\ \hline
Sichtfeld & $40^\circ \times 40^\circ$ & $57^\circ \times 43^\circ$ \\ \hline
Max Bildrate & 40 fps & 30 fps \\ \hline
Messbereich & 0.3 $\rightarrow$ 7.0 m & 1.2 $\rightarrow$ 3.5 m (mit Xbox Software) \\ \hline
Lange der Tiefdaten & 8 bit (unsigned char) & 11 bit \\ \hline
\end{tabular}
\caption{Die technische Daten von PMD Kamera und Kinect}
\label{PMD and Kinect}
\end{center}
\end{table}

\subsection{Daten der PMD Kamera}
Die PMD Kamera CamCube kann insgesamt 4 verschiedenen Vermessungsdaten ausgeben. Sie sind Amplitude, Intensität, Distanz und 3D Koordinaten. Die erste Zwei und letzte Zwei Typen der Daten können durch die Dimension in zwei Gruppen unterteilt werden. 

\subsubsection{2D Daten}
Die Intensität bezieht sich auf Graustufen. Nach einer Abbildung können diese Graustufen auf das Intervall 0 bis 255 beschränkt werden und das Ergebnis ist das Bild einer normalen Schwarz-Weiß Kamera. Die Amplitude zeigt die Stärke der Beleuchtung, die vom Objekt wegen des aktiven Sendersignal von PMD Kamera selbst reflektiert wird. Dieser Wert kann die Qualität der Distanzinformation schätzen, d.h. das Objekt weit von Kamera liefert niedriger Amplitude als das Objekt in der Nähe von der Kamera, wenn sie mit identischem Material dargestellt werden. An der Gegenseite sind die Merkmalen mit höherem Rückstrahlvermögen durch Amplitudedaten einfacher betrachtet, was für die Erkennung der großen künstlichen Marken in unserer Arbeit sinnvoll ist.   

\subsubsection{3D Daten}
Die PMD Kamera liefert 3D Daten in zwei Formen: die reine Distanzinformation und die 3D Koordinaten. Die Distanzinformation ist die gemessene Distanz zwischen der Kamera und Objekt, was direkt durch die Formel \eqref{tof1} berechnet wird. Bezüglich dieser Distanzinformation und der 2D Daten der normalen Kamera werden die 3D Koordinaten innerhalb der PMD Kamera berechnet und können durch die Schnittstelle abgefragt werden. Die Abbildung~\ref{C3D} zeigt die Visualisierung einer Szene mit jeweils der 3D Koordinaten und Distanzinformation von PMD Kamera. Eine Transformation ist notwendig, wenn man direkt die Distanzinformation im kartesischen Koordinatensystem visualisieren möchte.

\begin{figure}[bft]
\centering
\includegraphics[scale=0.45]{Abbildungen/Compare-3D-Dis}
\caption{Die Visualisierung von 3D Koordinaten(link) und Distanzinformation(recht).}
\label{C3D}
\end{figure}

\section{Vorverarbeitung}
\subsection{Schwellwert basierte Segmentierung}
Um das bessere Erkennungsergebnis zu erhalten, sollen die wesentlichen Bereiche von der Umgebung getrennt werden. In unserer Arbeit wird eine Schwellwert basierte Segmentierung bezüglich der 3D Daten verwendet. Eine Schwellwert basierte Segmentierung kann als eine Abbildung $f$ vom originalen Bild $I$ zum Ergebnisbild $H$ definiert werden:

\[
f: I \xmapsto{} H
\]

mit 

\begin{equation}
H_{ij} = 
\begin{cases}
1 & \text{für } I_{ij} > \Theta \\
0 & \text{sonst}
\end{cases}
\end{equation}

wobei $\Theta$ der eingegebene Schwellwert ist.
 
\subsection{Kontrollieren der Helligkeit und Kontrast}
Außer der Umgebung beeinflussen die Helligkeit und der Kontrast die Qualität bzw. Stabilität der Markenerkennung. Deshalb ist die Optimierung dieser zwei Parameter in der Vorverarbeitungsphase notwendig. In dieser Arbeit wird ein Affine-Operator für jedem Punkt durchgeführt, um die geeignete Helligkeit bzw. den Kontrast zu bestimmen. Der Affine-Operator ist eine Abbildung von originalem Bild $I$ zum Ergebnisbild $H$ mit:

\begin{equation}
H_{ij} = a I_{ij} + b
\end{equation}

wobei die Parameter $a \in R^+$ und $b \in R$ die Helligkeit und den Kontrast kontrollieren. Es gibt vier Möglichkeiten für die verschiedenen Zuordnungen dieser Parameter:

\begin{itemize}
\item $a>1$, $b=0$     Kontrasterhöhung
\item $0<a<1$, $b=0$ Kontrastminderung
\item $a=1$, $b>0$     Helligkeitserhöhung
\item $a=1$, $b<0$     Helligkeitsminderung
\end{itemize}

\section{Markenerkennung}
Wie im Abschnitt \ref{mErkennung} beschrieben hat, sind viele Erkennungsalgorithmen in der Open Source Library OpenCV realisiert. Wegen vieler Benutzung von OpenCV, wird der Vergleich dieser Algorithmen häufig gemacht. Im folgenden Abschnitt wird Ein davon zitiert, um den geeigneten Algorithmus für unsere Arbeit auszuwählen.
     
\subsection{Auswahl des Erkennungsalgorithmus}

\begin{figure}[bft]
\centering
\includegraphics[scale=0.22]{Abbildungen/SampleBild}
\caption{Die vier Beispielbilder. Von link nach recht sind Barbara, Lena, Peppers und Mandril. \cite{O11}}
\label{4Samp}
\end{figure}

\begin{figure}[bft]
\centering
\includegraphics[scale=0.7]{Abbildungen/Number-of-detected-features}
\caption{Anzahl der erkannten Merkmalen von alle vier Beispielbildern durch verschiedene Erkennungsalgorithmen. \cite{O11}}
\label{Nodf}
\end{figure}

Odessa hat in seinem Blog einen sehr gute Vergleich für alle Erkennungsalgorithmen von OpenCV durchgeführt \cite{O11}. Vier häufig benutzten Beispielbilder wurden betrachtet (s. Abb.~\ref{4Samp}).
\\
\\
Was besonders interessiert in seiner Arbeit ist der Vergleich über die Anzahl der betrachteten Punkte bzw. der durchschnittlichen Fehler. Wegen der verschiedenen Prinzipien erkennt der Algorithmus FAST viel mehr Merkmale als SURF und STAR. Den Unterschied sieht man deutlich in der Abbildung~\ref{Nodf}. Je mehr Punkte betrachtet werden, desto mehr Rauschen wird in das System gebracht, weil viele normale Pixel auch als Merkmale erkannt werden. Das ist offensichtlich ein negativer Einfluss für die weitere Analyse der Daten. Abbildung~\ref{Ate} zeigt den durchschnittlichen Fehler in Pixeln von den Punktpaaren, was durch gleichen Erkennungsalgorithmus von Bezugsbildern erkannt wird. Der Algorithmus STAR erzeugt deutlich weniger Fehler in der Erkennung, und das Ergebnis hängt auch leicht von der Eingabe ab. Wegen der niedrigeren Fehlerquote und besserer Konzentration an großen Merkmalen wie Klecks ist der STAR Algorithmus für die Erkennung der Objekte mit künstlichen Marken sehr geeignet.

\begin{figure}[bft]
\centering
\includegraphics[scale=0.7]{Abbildungen/Average-tracking-error}
\caption{Der durchschnittliche Fehler (in Pixeln) zwischen der assoziierten Punkte von zwei verfolgten Bildern. \cite{O11}}
\label{Ate}
\end{figure}

\subsection{CenSurE Algorithmus}
Der Algorithmus CenSurE (Center Surround Extrema) werden von Agrawal et al. am 2008 entwickelt \cite{AKB08}. Sie verbessern die SIFT bzw. SURT Verfahren durch Berücksichtigung aller Merkmale in allen Skalenraumen. Das Extremum durch den Skalen und Lagen werden ausgewählt, um die Merkmale zu bestimmen. Der Bi-level Filter wird hier statt Gaussian Filter verwendet, damit der Algorithmus in Echtzeit laufen kann, obwohl große Menge der Berechnung für allen Merkmale aller Skalenraume nötig sind. 

\subsubsection{Bi-level Filter}
Der Bi-level Filter ist eine einfache Approximation des Laplacian-Operators durch der Multiplikation der Bilder mit 1 und -1. Die Abbildung~\ref{bi-level} zeigt die Progression des Bi-level Filters mit verschiedenen Symmetrischen Stufen. Der kreisförmige Filter an linker Seite der Abbildung~\ref{bi-level} kann den Laplacian-Operator beste approximieren, ist aber leider schwierig zu implementieren. Deshalb werden die Progressionen der Filter durch Polygone angenähert, damit die Berechnung vereinfacht werden kann. Zum Vergleich der übrigen Formen der Abbildung~\ref{bi-level} liefert der Filter mit Achtecke die beste Leistung und der Filter mit Rechtecke die kürzeste Laufzeit. Diese Polygon-Filter können durch die integralen Bilder einfach dargestellt werden.  

\begin{figure}[bft]
\centering
\includegraphics[scale=0.6]{Abbildungen/Bi-level-filter2}
\caption{Progression der Center-Surround Bi-level Filter. Der Kreis ist die ideale voll symmetrische Approximation der Laplacian. Die Filter daneben von link nach recht haben niedriger Symmetrie, brauchen aber  wenigere Zeit zu implementieren. \cite{AKB08}}
\label{bi-level}
\end{figure}

\subsubsection{Integrale Bilder}
Ein integrales Bild $I$ ist eine mittlere Repräsentation des Bildes, was die Summe der Grauwerte von Bild $N$ mit Breite $x$ und Höhe $y$ enthält. 

\begin{equation}
I(x,y) = \sum _{x'=0}^x \sum_{y'=0}^y N(x',y')
\label{InteBild1}
\end{equation}   

Das integrales Bild ist rekursiv berechenbar und benötigt nur einmal Durchführung aller Pixeln des Bildes. Mithilfe des integralen Bildes kann die Intensität des beliebigen rechteckigen Bereiches einfach durch vier Additionen berechnet werden. Die Erweiterung des integralen Bildes wird für die Berechnung der Polygonen Filter benutzt. Die Kombination zweier verschiedenen schrägen integralen Bilder kann den für Polygone benötigten trapezförmigen Bereich einfach darstellen. Die mathematische Beschreibung des schrägen integralen Bildes ist:

\begin{equation}
I_\alpha(x,y) = \sum_{y'=0}^y \sum_{x'=0}^{x+\alpha(y-y')} N(x',y')
\label{InteBild2}
\end{equation}

wobei $\alpha$ den schrägen Winkel erklärt. Wenn $\alpha=0$, ist die Formel \eqref{InteBild1} genau so wie die Formel \eqref{InteBild2}, und beschreibt ein standardes rechteckiges integrales Bild. Die im Abbildung~\ref{bi-level} gezeigte Achtecke-Filter und Sechsecke-Filter können mit jeweils 3 bzw. 2 Trapezen schnell aufgebaut werden.
  
\subsubsection{Non-maximal Suppression}
Non-maximal Suppression ist eine Strategie, die das lokale Extremum finden kann. Die Response des Pixels wird unterdrückt, wenn es ein Pixel in seiner Nachbarschaft für Lage bzw. Skala gibt, dessen Response größer oder kleiner als das betrachtende Pixel ist. Die Pixeln mit entweder Maximum oder Minimum Response werden als Merkmale bekannt. Der Suchumfang wird in der Arbeit von Agrawal als 3x3x3 eingestellt, d.h. 8 Pixeln um dem betrachteten Pixel und jeweils 9 Pixeln im zwei benachbarten Skalenraumen, werden zusammen berücksichtigt. Die Pixeln mit höherer Response können zwischen der Transformation des Bildes stabiler wieder erkannt werden, deshalb nach der Non-maximal Suppression werden die ausgewählten Extremums noch mal durch einem Schwellwerte-Filter gefiltert, um die besten Merkmale zu bestimmen. 
  
\subsection{Kalman-Filter}

\subsubsection{Zustandsraummodellierung}
Das Kalman-Filter ist basiert auf einem linearen dynamischen System auf diskretisiertem Zeitraum. Die Zustandsgleichung des Systems wird häufig durch eine Differenzengleichung beschrieben. In vielen Fällen werden die Zuständen nur durch einem voneinander getrennten Zeitpunkt bestimmt. Kalman hat den Sonderfall der lediglich linearen Abhängigkeit der Zustände untereinander betrachtet, und vereinfachte die Zustandsgleichung zur linearen Differenzengleichung:

\begin{equation}
X_k = F_{k-1} X_{k-1} + B_{k-1} u_{k-1} + w_{k-1} 
\end{equation}

Der Index $k$ bzw. $k-1$ beziehen sich auf dem Zeitpunkt $t_{k}$ und $t_{k-1}$, wobei $t_k = t_0 + k \Delta t$ und $t_0$ der Anfangszeitpunkt und $k$ eine natürliche Zahl von Interesse ist. Deshalb beschreibt der mehrdimensionale Vektor $X_k$ den Zustand des Systems am Zeitpunkt $t_k$. Die Matrix $F_{x-1}$ ist die Übergangsmatrix für die zeitlich aufeinanderfolgenden Zustände $X_k$ und $X_{k-1}$. Die Matrix $B_{k-1}$ und Kontrollvektor $u_{k-1}$ stellen den deterministischen Anteil der weiteren äußeren Einflüsse auf das System dar.  Die zufälligen, nicht erfassbaren Komponenten der äußeren Einflüssen werden durch der stochastischen Größe $w_{k-1}$ geschätzt, die einer Normalverteilung mit Mittelwert 0 und Kovarianz $Q_{k-1}$ folgt.

\[
w_{k-1} \sim N(0,Q_{k-1})
\]

Wegen dieser Zufallsvariable bilden die Menge aller Zustandsvektoren eine Markow-Kette, d.h. der Zustand zu einem Zeitpunkt $k$ hängt lediglich vom unmittelbaren zeitlichen Vorgänger an $k-1$ ab.
\\
\\
Die Beobachtungen des Systems werden aus modellierbarer Verzerrung und unvorhersagbarem Messrauschen bestehlt.

\begin{equation}
Z_k = H_k X_k + v_k
\end{equation} 

$Z_k$ bezieht sich auf die Messung am Zeitpunkt $k$. Die Multiplikation von der Beobachtungsmatrix $H_k$ und Zustandsvektor $X_k$ beschreibt die linear Approximation der Verzerrung des Systems. Das Rauschen $v_k$ wird im Kalman-Filter als zeitlich unkorreliert und normalverteilt angenommen.

\[
v_k \sim N(0,R_k)
\]

\subsubsection{Das Kalman-Filter}
Das Ziel eines Filters ist durch die Informationen einer Messreihe die Zustände besser schätzen zu können. Da die Rauschterme $w$ und $v$ für alle Zeit die Normalverteilung erfüllen, können die zeitdiskreten Zustände $X_k$ auch durch einer Normalverteilung mit dem Mittelwert $\hat{x}_k$ und der Kovarianz $\hat{P}_k$ ermessen werden.

\[
\hat{X}_k \sim N(\hat{x}_k , \hat{P}_k)
\]

Die Idee des Kalman-Filter ist, eine rekursive Formulierung aufzubauen, die aber nur die Schätzung vorheriges Zeitpunkts und aktuelle Messung benötigt, um die Schätzung des aktuellen Zeitpunkt zu bestimmen. Es gibt hauptsächlich zwei Phase im Kalman-Filter.

\textbf{Prädiktion}
\\
In dem ersten Schritt dieser Phase wird eine vorangegangene Schätzung $X_{k|k-1}$ für aktuellen Zeitpunkt vorausgesagt.

\begin{equation}
\hat{x}_{k|k-1} = F_{k-1} \hat{x}_{k-1} + B_{k-1} u_{k-1}
\end{equation}

Die Indizierungsschreibweise $k|k-1$ bezieht sich auf der Bedingtheit zu den Zeitpunkten $k$ und $k-1$. Die Kovarianz gilt:

\begin{equation}
\hat{P}_{k|k-1} = F_{k-1} \hat{P}_{k-1} F_{k-1}^T + Q_{k-1}
\end{equation}

\textbf{Korrektur}
\\
Die Vorhersagen von letztem Schritt werden hier durch die neue Messung korrigiert.

\begin{equation}
\hat{x}_k = \hat{x}_{k|k-1} + \hat{K}_k \tilde{y}_k
\end{equation}

und 

\begin{equation}
\hat{P}_k = \hat{P}_{k|k-1} - \hat{K}_k S_k \hat{K}_k^T
\end{equation}

Die Hilfsgröße Innovation:

\[
\tilde{y}_k = Z_k - H_k \hat{x}_{k|k-1}
\]

beschreibt, wie genau die vorhergesagten Schätzungen mithilfe der Beobachtungsgleichung den aktuellen Messungen approximieren. $S_k$ bezieht sich auf der Residualkovarianz, was gilt:

\[
S_k = H_k \hat{P}_{k|k-1} H_k^T + R_k
\]

und $\hat{K}_k$ ist die zugehörige Kalman-Matrix.

\[
\hat{K}_k = \hat{P}_{k|k-1} H_k^T S_k^{-1}
\]

\section{Registrierung}
\subsection{Singulärwertzerlegung}
Sei M eine komplexe $m \times n$ Matrix mit Rang r. Dann bezeichnet die Singulärwertzerlegung das Produkt:

\begin{equation}
M = U \Sigma V^*
\end{equation}

wobei $U$ eine Unitäre Matrix mit Größe $m \times m$ und $V^*$ die Adjungierte einer Unitäre Matrix mit Größe $n \times n$ ist. $\Sigma$ bezieht sich auf eine $m \times n$ Diagonalmatrix:

\[
\Sigma = 
\begin{pmatrix}
\sigma_1 & & & \vline & & \vdots & \\
& \ddots & & \vline & \cdots & 0 & \cdots \\
& & \sigma_r & \vline & & \vdots & \\
\hline
& \vdots & & \vline & & \vdots & \\
\cdots & 0 & \cdots & \vline & \cdots & 0 & \cdots \\
& \vdots & & \vline & & \vdots & 
\end{pmatrix}
\]

mit $\sigma_1 \geq \cdots \geq \sigma_r > 0$, wobei $\sigma_i , i=1,\ldots , r$ als die Singulärwerte von $\Sigma$ genannt werden.

\subsection{Korrespondenzuntersuchung durch Singulärwertzerlegung}
Mithilfe der Singulärwertzerlegung haben Scott und Longuet-Higgins einen Algorithmus zur Bestimmung der assoziierenden Merkmale entwickelt. Seien $I$ und $J$ zwei nachfolgende Bilder und haben jeweils $m$ und $n$ Merkmale, die als $I_i (i=1,\ldots ,m)$ und $J_j (j=1,\ldots ,n$) bezeichnet werden. Dann wird eine $m \times n$ Matrix $G$ mit den Elementen

\[
G_{ij} = exp(- \frac{r_{ij}^2}{2 \sigma^2})
\]

definiert, wobei $r_{ij}$ den Abstand zwischen Merkmale $I_i$ und $J_j$ beschreibt. $\sigma$ wird als einen Standard für Abstand definiert, wodurch das Vergrößern oder Verkleinern der Verschiebung des Objekts geschätzt werden kann. Der Wert von $G_{ij}$ nimmt durch die Erhöhung der Distanz von 1 bis 0 monoton ab. Der zweite Schritt des Algorithmus von Scott und Longuet-Higgins ist die Singulärwertzerlegung der Matrix $G$.

\[
G = TDU
\]

wobei $T$ und $U$ die Unitäre Matrix mit jeweils Größe $m \times m$ und $n \times n$ sind, und $D$ eine Diagonalmatrix ist. Sei $E$ eine neue Matrix mit gleicher Größe von $D$, in der aber jedes diagonale Element als 1 ersetzt wird. Nach Austausch der Matrix $D$ durch Matrix $E$ erhält man eine neue orthogonale Matrix:

\[
P = TEU
\]

Die Aufgabe des dritten Schritts ist das Element $P_{ij}$ zu finden, was gleichzeitig das Maximum der Reihe und Spalte ist. Wenn $P_{ij}$ diese Bedingung erfüllt, sagt man, dass es eine Eins zu Eins Korrespondenz zwischen den Merkmalen $I_i$ und $J_j$ gibt. Der ganze Algorithmus kann durch folgendem Pseudocode erklärt werden. 

\begin{algorithm}                      % enter the algorithm environment
\caption{Bestimmung der Korrespondenz der Merkmalen von zwei Bildern}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
    \State $I,J,\sigma, Result$
    \For{$i=1 \to m$, $j=1 \to n$}
    	\State $r_{ij} \gets Dis(I_i, J_j)$
    	\State $G_{ij} \gets exp(-\frac{r_{ij}^2}{\sigma^2})$
    \EndFor
    \State $T,U \gets$ Singulärwertzerlegung von G
    \State $E \gets m \times n$ Diagonalmatrix mit $E_{ii} = 1$
    \State $P \gets TEU$
    \For{$i=1 \to m$}
    	\State $MaxSpalteIndex[i] \gets$ Index der Spalte des maximalen Elements an Reihe $i$.
    	%\State $MaxSpalteIndex_i \gets Max$ 
    \EndFor
    \For{$i=1 \to m$}
    	\If {$P_{iMaxSpalteIndex[i]}$ ist Maximum der Spalte $MaxSpalteIndex[i]$}
    		\State $Result \gets$ Punktpaar($I_i, J_{MaxSpalteIndex[i]}$) 
    	\EndIf
    \EndFor 
\end{algorithmic}
\end{algorithm}


\section{Schätzung der Transformation}

\subsection{Quaternion}
%Das Quaternion
Ein Quaternion besteht aus einem Vektor mit 4 Elementen, wobei ein Element ein Skalar bezeichnet und die anderen drei eine Richtung im 3D Raum beschreiben. Quaternionen können aber auch als eine Erweiterung der komplexen Zahlen betrachtet werden, deren Imaginärteil nach drei neuer Zahlen $i$, $j$ und $k$ entwickelt werden. Eine Normalform der Quaternion findet man im unten:

\[
q = q_0 + i q_x + j q_y + k q_z
\]

$i$, $j$ und $k$ erfüllen die sogenannte Hamilton-Regeln:

\[
i^2 = j^2 = k^2 = i j k = -1 
\]
\[
ij = k, \quad jk = i, \quad ki = j 
\]
\[
ji = -k, \quad kj = -i, \quad ik = -j
\] 

Ein andere Form mit getrennten Realteil und Imaginärteil wird im Folgenden definiert:

\begin{equation}
\label{QForm2}
q = (q_0, \vec{q})
\end{equation}

wobei $q_0 \in \mathbb{R}$ ein Skalar und $\vec{q} \in \mathbb{R}^3$ ein Vektor ist. Sei $r$ ein andere Quaternion mit:

\[
r = r_0 + i r_x + j r_y + k r_z
\]

Analog zum Vektoren im $\mathbb{R}^4$ wird das Skalarprodukt zwischen zwei Quaternion definiert als:

\[
\langle q, r \rangle := q \cdot r := q_0 r_0 + q_x r_x + q_y r_y + q_z r_z
\]

Weiterhin kann die Quaternionmultiplikation mithilfe der Form \eqref{QForm2} berechnet als:

\begin{align}
qr & = (q_0 r_0 - \vec{q} \cdot \vec{r} , \quad q_0 \vec{r} + \vec{q} r_0 + \vec{q} \times \vec{r}) \\
\label{QMulti}
& = (q_0 r_0 - q_x r_x - q_y r_y - q_z r_z) \nonumber \\
& + i ( q_0 r_x + q_x r_0 + q_y r_z - q_z r_y ) \nonumber \\
& + j ( q_0 r_y - q_x r_x + q_y r_0 + q_z r_z ) \nonumber \\
& + k ( q_0 r_z + q_x r_y - q_y r_x + q_z r_0 )
\end{align} 

Die rechte Multiplikation von $r$ in Formel \eqref{QMulti} kann aber auch zum einen links multiplizierten Matrix umschrieben werden.

\begin{equation}
qr = 
\begin{pmatrix}
r_0 & -r_x & -r_y & -r_z \\
r_x & r_0 & r_z & -r_y \\
r_y & -r_z & r_0 & r_x \\
r_z & r_y & -r_x & r_0
\end{pmatrix}
 = \mathbf{R} q
\end{equation}

Das konjugierte Quaternion von $q$ ist definiert als:

\[
\overline{q} = q_0 - i q_x - j q_y - k q_z
\]

Das Produkt eines Quaternion und dessen Konjugierte ist eine nicht negative reelle Zahl.

\[
q \cdot \overline{q} = q_0^2 + q_x^2 + q_y^2 + q_z^2 
\]

Mithilfe des konjugierten Quaternion kann man die Länge des Quaternion $|q|$ definieren:

\[
|q| = \sqrt{q \cdot \overline{q}}
\]

Ist die Länge eines Quaternion gleich 1, nennt man das Quaternion ein Einheitsquaternion. Für ein Einheitsquaternion gilt:

\[
q \cdot \overline{q} = 1 \iff \overline{q} = q^{-1}
\]

D.h. die Inverse und Konjugierte sind identisch. Für jedes Einheitsquaternion $q \neq \pm 1$ gibt es eine entsprechende Polardarstellung:

\begin{equation}
q = \cos \alpha + \mathit{v} \cdot \sin \alpha
\label{polarQ}
\end{equation}

mit $\alpha = \arccos (q_0) \in (0,\pi)$ und $v = \frac{1}{\sin \alpha} (i q_x + j q_y + k q_z)$. 

\subsection{Beschreibung der Drehungen im Dreidimensionalen Raum mit Quaternionen}
Die Drehungen im dreidimensionalen Raum können durch die Einheitsquaternionen sehr gut beschriebt werden. Eine Abbildung der Rotation $\rho_q$ kann in folgender Form definiert werden:

\[
\rho_q : x \rightarrow q x \overline{q}
\] 

wobei $q$ ein Einheitsquaternion und $\overline{q}$ dessen Konjugierte ist. Mithilfe der Polardarstellung \eqref{polarQ} kann die Abbildung $\rho_q$ sich auf eine Drehung im $\mathbb{R}^3$ um die Achse $\mathit{v}$ mit Winkel $2\alpha \in (0, 2\pi)$ beziehen. Die entsprechende orthogonalen Matrix von $q$ ist

\begin{equation}
R =
\begin{pmatrix}
q_0^2 + q_x^2 - q_y^2 - q_z^2 & 2q_x q_y - 2q_0 q_z           & 2q_x q_z + 2q_0 q_y \\
2q_x q_y + 2q_0 q_z           & q_0^2 - q_x^2 + q_y^2 - q_z^2 & 2q_y q_z - 2q_0 q_z \\
2q_x q_z - 2q_0 q_y           & 2q_y q_z + 2q_0 q_z           & q_0^2 - q_x^2 - q_y^2 + q_z^2
\end{pmatrix}
\end{equation} 

was zur Drehgruppe SO(3) gehört und eine Drehung in der Matrixform repräsentiert.

\subsection{Orientierung mit Einheitsquaternion}
Das Verfahren für die Orientierung der Objekte mithilfe der Quaternionen wurde erst von Horn im 1987 veröffentlicht \cite{H87}. Seien $D$ und $M$ zwei Punktmengen mit gleicher Größe $n$. Dann kann die Transformation zwischen den Punkten von zwei Menge formuliert werden als:

\begin{equation}
d_i = \mathbf{R} m_i + \mathbf{T} + e_i
\end{equation}

wobei $d_i$ und $m_i$ die i-ten Punkte der Punktmengen $D$ bzw. $M$ bezeichnen. $\mathbf{R}$ ist die Rotationsmatrix und $\mathbf{T}$ ist die Translationsmatrix. $e_i$ beschreibt den Fehler für die Transformation, und kann umformuliert werden als:

\begin{equation}
\label{QError}
e_i = d_i - \mathbf{R} m_i + \mathbf{T}
\end{equation}


Das Ziel des Verfahrens ist, eine Rotations- bzw. Transformationsmatrix mit minimalem Fehler zu finden, dadurch wird die Summer des Quadrats von $e_i$ betrachtet.

\begin{equation}
\sum_{i=1}^n \| e_i \|^2 = \sum_{i=1}^n \| d_i - \mathbf{R} m_i + \mathbf{T} \|^2 
\end{equation} 

Seien $\overline{d}$ und $\overline{m}$ die Schwerpunkte jeweils der Punktmenge $D$ und $M$. Dann gilt

\[
\overline{d} = \frac{1}{n} \sum_{i=1}^n d_i 
\quad \quad
\overline{m} = \frac{1}{n} \sum_{i=1}^n m_i
\]

Der Abstand von jedem Punkt zum Schwerpunkt wird berechnet als:

\[
d_i' = d_i - \overline{d}
\quad \quad
m_i' = m_i - \overline{m}
\]

und die Summe der Abstände erfüllt natürlich

\begin{equation}
\label{QDis}
\sum_{i=1}^n d_i' = 0
\quad und \quad
\sum_{i=1}^n m_i' = 0
\end{equation}

Dann kann der Fehler in Formel \eqref{QError} mit den Abständen zum Schwerpunkt $\overline{d}$ und $\overline{m}$ umgeschrieben werden:

\begin{equation}
e_i = d_i' - \mathbf{R} m_i' + \mathbf{T}'
\end{equation}

wobei $\mathbf{T}'$ als 

\[
\mathbf{T}' = \mathbf{T} - \overline{d} + \mathbf{R} \overline{m}
\]

definiert wird. Analog kann die Summe des Quadrats des Fehlers neu formuliert werden.

\begin{align}
\label{QError2}
\sum_{i=1}^n \| e_i \|^2 &=
\sum_{i=1}^n \| d_i' - \mathbf{R} m_i' + \mathbf{T}' \|^2 \nonumber \\
&= \sum_{i=1}^n \| d_i' - \mathbf{R} m_i' \|^2 - 2\mathbf{T}' \cdot \sum_{i=1}^n (d_i' - \mathbf{R} m_i')
+ n \| \mathbf{T}' \|^2
\end{align}

Wegen \eqref{QDis} ist der zweite Term gleich 0. Der dritte Term kann nicht negativ sein und wird 0, wenn der gesamte Fehler minimiert wird. D.h.:

\begin{align}
\label{QTran}
& \mathbf{T}' = \mathbf{T} - \overline{d} + \mathbf{R} \overline{m} = 0 \nonumber \\
\Rightarrow & \mathbf{T} = \overline{d} + \mathbf{R} \overline{m}
\end{align}

Die Formel \eqref{QTran} berechnet direkt die Transformationsmatrix durch die Rotationsmatrix und die Schwerpunkte der beiden Punktmengen. Der erste Term von \eqref{QError2} kann zu

\begin{equation}
\sum_{i=1}^n \| d_i' - \mathbf{R} m_i' \|^2 = \sum_{i=1}^n (d_i'^t d_i' + m_i'^t m_i' - 2 d_i'^t \mathbf{R} m_i')
\end{equation}

weiter formuliert werden. Dann wird die Minimierung des Fehlers durch die Bestimmung des Maximum der Summe

\begin{equation}
\sum_{i=1}^n d_i'^t \mathbf{R} m_i'
\end{equation}

erreicht. Durch Ersetzen der Rotationsmatrix mit Quaternion wird das maximierte Problem umformuliert als:

\[
\sum_{i=1}^n (q m_i'' \overline{q}) \cdot d_i''
\]

wobei $m_i'' = (0, m_{i,x}', m_{i,y}', m_{i,z}')$ und $d_i'' = (0, d_{i,x}', d_{i,y}', d_{i,z}')$ die erweiterte Quaternion für Punkte $m_i'$ bzw. $d_i'$ sind.
Dann gilt:

\begin{align}
\label{qmdq}
\sum_{i=1}^n (q m_i'' \overline{q}) \cdot d_i''
& = \sum_{i=1}^n (q m_i'' \overline{q}) \cdot ( d_i'' q \overline{q}) \nonumber \\
& = \sum_{i=1}^n (q m_i'') \cdot (d_i'' q)
\end{align}

Die beide Multiplikationen in Klammer können als Formel \eqref{QMulti} zum Produkt von einem Quaternion und einer Matrix umschrieben werden.

\[
q m_i'' = 
\begin{pmatrix}
0 & -m_{i,x}' & -m_{i,y}' & -m_{i,z}' \\
-m_{i,x}' & 0 & -m_{i,z}' & -m_{i,y}' \\
-m_{i,y}' & -m_{i,z}' & 0 & -m_{i,x}' \\
-m_{i,z}' & -m_{i,y}' & -m_{i,x}' & 0
\end{pmatrix}
 = \mathbf{M}_i q
\]

und 

\[
d_i'' q = 
\begin{pmatrix}
0 & -d_{i,x}' & -d_{i,y}' & -d_{i,z}' \\
d_{i,x}' & 0 & -d_{i,z}' & d_{i,y}' \\
d_{i,y}' & d_{i,z}' & 0 & -d_{i,x}' \\
d_{i,z}' & -d_{i,y}' & d_{i,x}' & 0
\end{pmatrix}
 = \mathbf{D}_i q
\]

Dann kann \eqref{qmdq} weiter ableitet werden:

\begin{align}
\label{qNq}
 \sum_{i=1}^n ( \mathbf{M}_i q) \cdot ( \mathbf{D}_i q)
 & = \sum_{i=1}^n q^t \mathbf{M}_i^t \mathbf{D}_i q \nonumber \\
 & = q^t \Big( \sum_{i=1}^n \mathbf{M}_i^t \mathbf{D}_i \Big) q \nonumber \\
 & = q^t \Big( \sum_{i=1}^n \mathbf{N}_i \Big) q \nonumber \\
 & = q^t \mathbf{N} q
\end{align}
 
wobei $\mathbf{N}_i = \mathbf{M}_i^t \mathbf{D}_i$ ist, und $\mathbf{N}$ die Summe von $\mathbf{N}_i$ beschreibt. Sei $\mathbf{H}$ die Summe der Kreuzprodukten des Punktpaars von Punktmengen $D$ und $M$.

\[
\mathbf{H} = \sum_{i=1}^n m_i d_i^t
\]

Es ist deutlich, dass die Größe der Matrix $\mathbf{H}$ 3 $\times$ 3 ist, deshalb kann $\mathbf{H}$ auch als

\[
\mathbf{H} = 
\begin{pmatrix}
S_{xx} & S_{xy} &S_{xz} \\
S_{yx} & S_{yy} &S_{yz} \\
S_{zx} & S_{zy} &S_{zz} 
\end{pmatrix}
\]  
  
geschrieben werden, wobei

\[
S_{xx} = \sum_{i=1}^n m_{i,x}' d_{i,x}' \quad
S_{xy} = \sum_{i=1}^n m_{i,x}' d_{i,y}' 
\]

usw. Dann kann die Matrix $\mathbf{N}$ im \eqref{qNq} durch die Elemente von $\mathbf{H}$ dargestellt werden als:

\begin{equation}
\mathbf{N} = 
\begin{pmatrix}
S_{xx} + S_{yy} + S_{zz} & S_{yz} - S_{zy} & S_{zx} - S_{xz} & S_{xy} - S_{yx} \\
S_{yz} - S_{zy} & S_{xx} - S_{yy} - S_{zz} & S_{xy} + S_{yx} & S_{zx} + S_{xz} \\
S_{zx} - S_{xz} & S_{xy} + S_{yx} & -S_{xx} + S_{yy} - S_{zz} & S_{yz} + S_{zy} \\
S_{xy} - S_{yx} & S_{zx} + S_{xz} & S_{yz} + S_{zy} & -S_{xx} - S_{yy} + S_{zz} 
\end{pmatrix}
\end{equation}

Nach dem Beweis von Horn \cite{H87} wird die Formel \eqref{qNq} Maximum, genau dann wenn $q$ der zu dem maximalen positiven Eigenwert der Matrix $\mathbf{N}$ entsprechende Eigenvektor ist. 

\section{Objekterkennung}

\subsection{DBSCAN}
DBSCAN, kurz von dem englischen Name Density-Based Spatial CLustering of Applications with Noise, ist ein auf Dichte basierter Data-Mining-Algorithmus. Die Hauptidee des Algorithmus hängt stark von dem Begriff ,,Dichteverbundenheit'' ab, was durch folgenden Definitionen erklärt wird.
\\
\\
Seien $D$ eine Punktmenge im Raum $\mathbb{R}^n$ und $Dist(p,q)$ eine darauf definierte Distanzfunktion. $\epsilon$ und MinPts sind zwei Eingaben des Algorithmus.

\begin{definition}
\textsf{$\epsilon$-Umgebung} $N_{\epsilon}(p)$ ist eine Menge der Punkte um $p$, die erfüllt
\[
N_{\epsilon}(p) = \{ q \in D | Dist(p,q) \geq \epsilon \}
\]
\end{definition}

\begin{definition}
Ein Punkt $p$ ist \textsf{direkt Dichte-erreichbar} zum Punkt $q$, g.d.w:
\begin{align*}
1) \quad & p \in N_{\epsilon}(q)  \nonumber \\
2) \quad & | N_{\epsilon}(q) | \geq MinPts \nonumber
\end{align*}
\end{definition}

\begin{definition}
Ein Punkt $p$ ist \textsf{Dichte-erreichbar} zum Punkt $q$, g.d.w es eine Kette von Punkten $p_1, \ldots , p_n$ mit $p_1 = p$ und $p_n = q$ gibt, wobei $p_{i+1}$ \textsf{direkt Dichte-erreichbar} zum $p_i$ für alle $i \in [1,n]$ ist.
\end{definition}

\begin{definition}
Zwei Punkte $p$ und $q$ heißt \textsf{Dichte-verbunden}, g.d.w es ein Punkt $o$ gibt, wobei $p$ und $q$ jeweils zum $o$ \textsf{Dichte-erreichbar} sind.
\end{definition}

Mithilfe dieser Definitionen der Beziehung zwischen dem Punkten kann man jetzt eine einzige Definition des Clusters ausgeben.

\begin{definition}
Sei $C$ eine nicht leere Teilmenge von $D$. Dann heißt $C$ ein Cluster, wenn die folgenden zwei Bedingungen erfüllt werden:
\begin{align*}
1) \quad & \text{für $\forall p, q \in D$, wenn $p \in C$ und $q$ ist \textsf{Dichte-erreichbar} zum $p$, dann gilt } q \in C \nonumber \\
2) \quad & \text{für $\forall p, q \in C$, $p$ ist \textsf{Dichte-verbunden} zum $q$} \nonumber
\end{align*}
\end{definition}

Dann können alle Punkte von $D$ in drei verschiedene Type zusammengefasst werden.

\begin{itemize}
\item Kernpunkt: Der Punkt, die Größe dessen $\epsilon$-Umgebung größer als MinPts ist.
\item Grenzpunkt: Der Punkt, dessen $\epsilon$-Umgebung nicht genug groß ($<$MinPts), aber zu anderen Punkten Dichte-erreichbar ist.
\item Geräusch: Der Punkt, der zu keinem Cluster gehört.  
\end{itemize}

\begin{figure}[ftb]
\centering
\includegraphics[scale=0.3]{Abbildungen/DBSCAN}
\caption{Ein Beispiel für die drei Typen der Punkte in DBSCAN-Algorithmus. Der rote Punkt A ist ein Kernpunkt. Die gelbe Punkte B und C sind die Grenzpunkte, die von roten Punkten Dichte-erreichbar sind. Wegen keine Dichte-Verbindung zwischen blau Punkt N und andere Punkte, wird N als Geräusch erkannt. \cite{DWiki}}
\label{DBSCAN}
\end{figure}

Abbildung~\ref{DBSCAN} zeigt ein Beispiel für alle diesen drei Typen des Punkts, wobei die Kernpunkte mit Rot, Grenzpunkte mit Gelb und Geräusch mit Blau beschrieben werden. Die Kreise zeigen die $\epsilon$-Umgebungen für die Punkte an ihrem Ursprüngen.
\\
\\
Das Algorithmus durchläuft für jeden Punkt von Punktmenge $D$ und die Lösung hängt von der Reihenfolge der Punkte nicht ab. Ein Kernpunkt soll zuerst gefunden werden, und dann die andere Punkte in ihrer $\epsilon$-Umgebung betrachtet werden. Zwei $\epsilon$-Umgebung werden verknüpft, wenn sie mindesten einen identische Punkt haben. Der genaue Ablauf des DBSCAN-Algorithmus findet man unten.

\begin{algorithm}                      % enter the algorithm environment
\caption{DBSCAN}          % give the algorithm a caption
\label{algDBSCAN}                      % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
	\State $D, \epsilon, MinPts$
	\State Setzen $C$ zum ersten Cluster
	\For {jede $P_i \in D$}
		\If {$P_i$ ist nicht besucht}
			\State Markieren $P_i$ als besucht
			\State $N = \{ P_j \in D | Dist(P_i, P_j)<\epsilon \}$
			\If {Anzahl der Elemente von $N$ $<$ MinPts}
				\State Markieren $P_i$ als Geräusch
			\Else
				\State Fügen $P_i$ in aktuellem Cluster $C$ ein
				\For {jede $P_j \in N$}
					\If {$P_j$ ist noch nicht besucht}
						\State Markieren $P_j$ als besucht
						\State $N' = \{ P_k \in D | Dist(P_j, P_k)<\epsilon \}$
						\If {Anzahl der Elemente von $N'$ $\geq$ MinPts}
							\State $N = N \cup N'$
						\EndIf 
					\EndIf
					\If {$P_j$ gehört zu keinem Cluster}
						\State Fügen $P_j$ in aktuellem Cluster $C$ ein
					\EndIf
				\EndFor
				\State Setzen $C$ zum nächsten Cluster
			\EndIf
		\EndIf
	\EndFor
\end{algorithmic}
\end{algorithm}

\subsection{Teilgraph Isomorphismus}
Die Objekterkennung bzw. Objektverfolgung werden vom Vergleich der Modellgraphen und Eingabegraphen realisiert. Ein für unsere Arbeit hilfreicher Algorithmus wurde von Rhijn und Mulder entwickelt \cite{AJ05}. Um das Problem von Graph Isomorphismus zu vereinfachen, werden nur ein Teilgraph $S_{min}$ von Modellgraphen betrachtet. $S_{min}$ soll ein vollständiges Graph sein und ein Modellgraph eindeutig bestimmen können. Zuerst wird ein Punkt $p_i$ von Eingabegraph ausgewählt und die Distanzen von dem zum allen seinen Nachbarn berechnet. Alle diese Kantenlänge werden mit den Kanten von Modellgraph verglichen, damit ein Kandidatenpunkt $v_k$ in Modellgraph gefunden werden kann, der genug identischen Kanten mit ausgewähltem Punkt $p_i$ hat. Zweite sollen drei Nachbarn von $p_i$ gefunden werden, die mit $p_i$ zusammen ein vollständiges Graph (Pyramid) darstellen können. Wenn ein Teilgraph von Modellgraph zum obigem vollständigen Graph assoziiert, wird endlich ein Teilgraph Isomorphismus zwischen den Eingabegraph und Modellgraph gefunden. Der Algorithm~\ref{isoAlgo} gibt eine genauere Beschreibung des Algorithmus von Rhijn und Mulder aus.

\begin{algorithm}
\caption{Teilgraph Isomorphismus}
\label{isoAlgo}
\begin{algorithmic}
	\State Modellgraph:$G_m$, Eingabegraph:$G_d$
	\For {jede $p_i \in G_d$}
		\For {jeder Nachbar $p_j$ von $p_i$}
			\For {alle Punktpaare $(v_k, v_l) \in G_m$} 
				\If {$dist(p_i, p_j) = dist(v_k, v_l)$}
					\State Fügen assoziierte Punktpaar $<p_j, v_l>$ zum $S_i$ ein
				\EndIf 
			\EndFor
			\If {$\| S_i \| \geq \| S_{min} \|$}
				%\State Fügen den Punkt $<p_i, v_k>$ zum Kandidaten $K$ ein
				\If {Drei Punktpaare in $S_i$ gefunden können, damit deren ersten Punkte mit $p_i$ ein Pyramid aufbauen können}
					\State Teilgraph Isomorphismus ist gefunden
					\State Break
				\EndIf
			\EndIf 
		\EndFor
	\EndFor
\end{algorithmic}
\end{algorithm}


