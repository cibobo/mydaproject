\chapter{Stand der Forschung}

3D Objekterkennung und Verfolgung kommt in vielen Anwendungsbereichen zum Einsatz. Daher wurden viele Algorithmen bzw. Systeme dafür in den vergangenen Jahrzehnten entwickelt. Ein gutes Beispiel ist das kommerzielle Erkennungssystem von VICON \cite{VIC}. In dem System werden 8 Kameras benutzt, die von verschiedenen Richtungen das Zielobjekt bzw. Person beobachten. Einige weiße Marken werden vorher am Ziel angebracht, damit seine Positionen und Bewegungen von den Kameras gut erkannt werden können. Nach Vergleichen der Bilder von verschiedenen Kameras kann ein 3D Modell des Ziels in Echtzeit erzeugt werden. Das System wird im Bereich von Computerspielen und Filmindustrie sehr oft benutzt. Ein anderes Beispiel ist das neue Gerät Kinect von Microsoft XBox360 \cite{KIN}. Eine 3D Kamera kann die 3D Daten von Spielern ansammeln, damit die Spieler das Spiel direkt mit ihren Körpern statt des traditionellen Kontroller steuern können. Die Analyseverfahren der Objekterkennung basieren auf unterschiedlichen Charakteristika der Objekte und sind für verschiedenen Typen von Objekten geeignet. In der Arbeit von Lepetit und Fua sind die aktuelle Verfolgungsverfahren in zwei große Gruppen unterschieden worden: auf Marken basierte Objektverfolgungen und auf natürlichen Merkmale basierte Objektverfolgungen. Die Verfahren in der zweiten Gruppe können weiter in kantenbasiertes Verfahren, optischer Fluss basiertes Verfahren, Templatebasiertes Verfahren, Punktebasiertes Verfahren und das SLAM-Verfahren unterteilt werden \cite{LF05}. Im folgenden Abschnitt werden kurz die Details jedes Verfahrens erklären.    

%In unserem System können alle Objekte in zwei Typen eingeteilt werden: die Objekte, die immer eine Seite zur Kamera richten, d.h. nur Bewegungen der Objekte in der Ebene von der Kamera beobachtet werden; und andere Objekte, die sich frei im Raum bewegen. Wir benennen den ersten Typ als feste Objekte z.B. der Arbeitsplatz, und den zweiten Typ als frei bewegte Objekte, z.B. das Werkzeug. Im Folgenden werden aktuelle Forschungsarbeiten über Objekterkennungsverfahren für beide Typen von Objekten erklären.


%\section{Feste Objekte}
%Das Problem für die Erkennung der festen Objekte kann als die Objekterkennung mit planaren Marken zusammengefasst werden. In diesem Bereich sind viele Systeme für die Erweiterte Realität implementiert worden. 

\section{Standardmarkenbasierte Verfahren}
Die Verfolgungsverfahren können in zwei Schritte unterteilt werden: zuerst der Informationen von Bildsequenzen ansammeln um dann die Position des erkannten Objekts zu bestimmen. Die vordefinierte Marken können in beiden Schritten mehr Information liefern, damit die Objekte schneller und einfacher verfolgt werden können. Deshalb sind in diesem Bereich viele Systeme für die Erweiterte Realität implementiert worden. Ein Echtzeitsystem für Erweiterte Realität wurde von Zhang und Navab für Objektverfolgung in einer Industrieumgebung realisiert \cite{ZN00}. Sie haben eine Gruppe von 4 Vierecken als eine Marke benutzt. Die Marke wird durch Farbe und weiße Flecken innerhalb der Vierecke kodiert. 
\\
\\
Ein anderes System heißt ARToolKit, was vom HITLab der Universität Washington entwickelt wird. Es ist eine bekannte Software-Bibliothek zur Entwicklung von Anwendungen für die Erweiterte Realität \cite{ART}. In ARToolKit wird ein Viereck mit schwarzer Umrandung als Marke benutzt. Das Muster in der Mitte kodiert die Marke und kann frei gewählt werden. Das Eingabebild wird zuerst in ein Binärbild umgewandelt und dann alle verbundenen schwarzen Pixel extrahiert. Die Figur innerhalb der schwarzen Umrandung wird segmentiert und mit dem früheren definierten Muster verglichen. Durch den Vergleich kann man die Projektivität zwischen Kamerakoordinatensystem und Musterkoordinatensystem bestimmen. 
\\
\\
ARToolKit liefert eine hohe Frame-Rate mit bis zu 30 fps bei niedrigem CPU-Bedarf. Eine dicke schwarze Umrandung garantiert die Stabilität des Systems und die Marke kann in niedriger Auflösung sehr gut erkannt werden. Ein anderer wichtige Vorteil ist, dass die Verfolgung der ARToolKit keine Initialisierung braucht. Dadurch wird nicht nur die Laufzeit am Anfang des Verfahren gespart, kann aber auch Chaos vermeiden, wenn die eingegebene Bildsequenz abgebrochen wird.   
%Wegen dieser Vorteile wird in unserem System ARToolKit benutzt werden, um die festen Objekte wie Arbeitsplätze zu erkennen.


%\section{Frei bewegte Objekte}
%Wegen der Bewegung in mehren Freiheitsgraden, ist die Erkennung der frei bewegten Objekte viele komplexer. Das System soll die komplette charakteristische Information des Objekts betrachten, um das gleiche Objekt wiederzuerkennen, wenn es noch mal unter die Kamera gebracht wird. Im wesentlichen beruhen die aktuellen Objekterkennungsverfahren auf Templates, Kanten und Punktes. 

\section{Verfahren basierend auf natürlichen Merkmalen}

\subsection{Kantenbasiertes Verfahren}
Das kantenbasierte Verfahren wurde in früheren Objektverfolgungssystemen häufig benutzt, weil es effizient und einfach zu realisieren ist \cite{LF05}. Die Hauptidee dieses Verfahrens ist entweder die Kanten des Objekts direkt von dem Bild herauszufinden und zu verfolgen, oder den Teil des Bildes mit starkem Gradient zu betrachten, damit man die Konturen des Objekts zum nächsten Zeitpunkt vorhersagen kann. RAPiD war eines der frühesten 3D Verfolgungsverfahren, das in Echtzeit laufen konnte \cite{H92}. Vacchetti und Lepetit haben ein neues, effizienteres Verfolgungsverfahren entwickelt, was mehr als eine Voraussagen für die ausgewählten Steuerpunkte darstellen \cite{VLF04}. Diese Erweiterung verstärkt die Stabilität der Verfolgung und erfüllt weiterhin die Echtzeitbedingung.   
%Falls ein Teil des Objekts von Händen oder anderem Werkzeug verdeckt wird, kann das Verfahren wegen des Verlustes der Kanteninformation keine richtige Lösungen liefern. Aus dem gleichen Grund entspricht das auf Punktwolke basiertes Objekterkennungsverfahren unseren Bedarf auch nicht. 

\subsection{Optischer Fluss basiertes Verfahren}
Der Optische Fluss ist ein Vektorfeld, das die Bewegungsrichtung und Bewegungsgeschwindigkeit für jeden Bildpunkt einer Bildsequenz bezeichnet. Die Berechnung des Optischen Fluss kann als eine Differentialgleichung zusammengefasst werden und das Lösungsverfahren wurde von Horn und Schunck entwickelt \cite{HS81}. Black und     Yacoob benutzten reine Optische Fluss basierte Verfahren für die Verfolgung kleiner Veränderungen auf menschlichem Gesicht, um den Gesichtsausdruck zu bestimmen \cite{BY97}. Außerdem wurde ein Verfolgungssystem für den Innerstadt Verkehr von Haag und Nagel durch die Verknüpfung der Information von Optischem Fluss und Kanten des Objekts implementiert \cite{HN99}.  


\subsection{Templatebasiertes Verfahren}
Im Templatebasierten Verfahren wird ein Objekt nicht durch lokale Merkmale z.B. Kanten oder Punkte, sondern durch das globale Charakteristikum erkannt und verfolgt. Das Verfahren ist geeignet für komplexe Objekte, die nicht einfach durch lokale Merkmale bezeichnet werden können \cite{LF05}. Der Lucas-Kanade Algortihmus wurde anfänglich entwickelt, um den Optischen Fluss zu berechnen \cite{LK81}, ist aber auch für die 2D templatebasierte Verfolgung nutzbar. Jurie und Dhome haben einen Algorithmus für die Verfolgung von ebenen Objekten mithilfe von Hyperebenen entwickelt \cite{JD01}. In ihrer Arbeit wurde die Approximation der Abbildung des Objekts auf Hyperebenen abgeschätzt, dadurch die Translation des Objekts bestimmt werden kann. 
%Das templatebasierte Verfahren braucht eine relative große Menge der Samples für verschiedene Deformation des Templates für jedes Objekt. Da das ganze Template in der Verfolgungsphase mit den Samples verglichen werden soll, braucht das Verfahren viel Zeit. Obwohl das Verfahren für einige komplexe Objekte effektiv ist, ist es für unsere Situation aber nicht geeignet \cite{LF05}. 

\subsection{Punktebasiertes Verfahren}
Der Unterschied zwischen dem punktebasierten Verfahren und den oben beschriebenen Verfahren ist, dass nur lokale Merkmale betrachtet werden. Im Vergleich zum Verfahren, das globale Merkmale behandelt, ist das Verfolgungsverfahren mit lokalen Merkmalen viel stabiler, wenn es Kollision für mehr Objekte gibt, oder die Messung der Merkmalen stark stört wird \cite{LF05}. Ein Verfahren wurde von Zhang et al. im Jahre 1995 realisiert, was die nicht kalibrierten Bilder als Eingabe benutzen kann \cite{Z95}. In dem Verfahren wird kein Modell der Epipolargeometrie verwendet, wodurch viele komplexen Berechnungen vermieden werden. Eine andere Möglichkeit für die Punkteverfolgung ist der Kanade-Lucas-Tomasi(KLT) Tracker, was auf der Arbeit von \cite{LK81} begründet wurde. Sie haben eine Approximation für den Unterschied zwischen zwei Bildern definiert. Mithilfe des Iterationsverfahrens von Newton-Raphson wird die Approximation minimiert. Dadurch kann die Translation des Objekts bestimmt werden. Tomasi erweiterte den Algorithmus von Lucas und Kanade mit einer besseren Strategie zur Auswahl von Merkmalen \cite{TK91}. Der dritte Schritt wurde von Shi und Tomasi vervollständigt \cite{ST94}. Sie verbesserten weiter die Auswahl der Punkte mit der Ähnlichkeit zwischen dem Anfangsbild und das aktuelle Bild. Diese Ähnlichkeit wird durch einem Modell von affiner Abbildung bestimmt. Außerdem benutzen sie gleichzeitig zweites Modell von reiner Translation, um das Objekt mit hoher Seriosität und Präzision zu verfolgen. 

\section{Markenbasierte Objekterkennung}
\label{MObjEr}
Rhijn und Mulder haben ein markenbasiertes Verfahren entwickelt, was das Verdeckungsproblem behandelt \cite{AJ05}. Einige runde, hoch reflektierende Marken werden auf dem Objekt angebracht. In der Initialisierungsphase speichert das System die Charakteristika des Objekts als einen 3-dimensionalen vollständigen Graph. Wenn das Objekt wiedererkannt werden soll, führt das System zuerst einen Kalibrationsalgorithmus durch, um die verschiedenen Objekte zu differenzieren. Dann vergleicht das System für jedes Objekt die sichtbaren Marken mit dem in der Initialisierungsphase gespeicherten vollständigen Graphen.  

\subsection{Markenerkennung}
Der erste Schritt der Markenbasierten Objekterkennung ist, alle angebrachten Marken zu erkennen. Die freie Programmbibliothek OpenCV liefert viele verschiedenen Algorithmen für Markenerkennung, und die Geschwindigkeit, Stabilität bzw. die Genauigkeit dieser Algorithmen werden von Odessa in seiner Ausarbeitung verglichen \cite{O11}. In diese Arbeit wird der Erkennungsalgorithmus STAR ausgewählt, wegen der niedrigen durchschnittlichen Fehler-Rate, was besonders wichtig für die Markenerkennung ist \cite{AKB08}. Außerdem betrachtet der STAR Algorithmus weniger Merkmale als andere Algorithmen, deshalb wird die gesamte Laufzeit der Markenerkennung verkürzt. Diese Eigenschaft entspricht genau unseren Anforderungen, weil nur wenige Marken an dem Objekt angebracht werden (weniger als 10 an jeder Oberfläche).

\subsection{Markenverfolgung}
Nach Bestimmung der Marken, sollen diese Marken in einer Bildsequenz verfolgt werden. Scott und Longuet-Higgins haben einen eleganten und einfachen Algorithmus erzeugt \cite{SL91}. Sie haben das Problem zu einer Matrix zusammengefasst, deren Elemente als die Distanz zwischen verschiedenen Merkmalen definiert werden. Durch eine Singulärwertzerlegung und Matrixersetzung werden die Abbildungen der Marken zwischen zwei Bildern bestimmt. Rhijn und Mulder verbesserten den Algorithmus von Scott und Longuet-Higgins. Sie haben die Elemente der Matrix neu definiert und fügten die Beschränkung von Epipolargeometrie ein \cite{AJ05}.  

\subsection{Schätzung der Transformation}
Für ein 3D Objekt ist die Markenverfolgung innerhalb von Bildern nicht ausreichend, um die komplette geometrische Information zu rekonstruieren. Deshalb soll die Pose des Objekts gleichzeitig bestimmt werden, damit ein räumlicher charakteristischer Graph für das Objekt erstellt werden kann. Natürlich kann man mit Hilfe der Ergebnisse der Markenverfolgung die relative Rotation und Translation des Objekts zwischen zwei Zeitpunkten berechnen, aber außerdem gibt es Verfahren, die durch Vergleich der Punktwolken von zwei Bildern direkt die Transformation des Objekts bestimmen können. Diese Verfahren wurden von Eggert et al. in ihrer Arbeit durch Merkmale und Lösungsverfahren in verschiedene Typen unterteilt \cite{ELF97}. Die Merkmale könnten die Oberfläche, die Kanten bzw. die Punkte sein. Die Verfahren, die auf Punkte basieren, werden im Praktisch häufig benutzt und sind geeignet für die Markenbasierte Objekterkennung \cite{ELF97}. Die Lösungsverfahren können in iterative Verfahren und geschlossene Form unterschieden werden.

\subsubsection{Geschlossene Form}
Ein effizientes Verfahren mit geschlossener Form für das Berechnen der Transformation wurde von Arun et al. zuerst am Jahr 1987 veröffentlicht \cite{AHB87}. Die Hauptidee des Verfahrens ist, eine approximierte Rotations- bzw. Translationsmatrix zwischen zwei aufeinander folgenden Bildern zu bestimmen, damit die Summe des Unterschieds zwischen den durch approximierte Transformation berechnete Positionen der Punkte und die genaue Positionen der Punkte minimiert wird. Dieses Verfahren basiert auf der Singulärwertzerlegung einer Korrelationsmatrix. Die Rotations- und Translationsmatrix werden am Ende ausgegeben. Wenn die zwei eingegebenen Punktwolken auf gleich Oberfläche liegen, liefert das Verfahren leider keine richtige Rotationsmatrix. Deshalb soll eine korrigierte Matrix darauf aufbauen, die von Umeyama \cite{U91} und Kanatani \cite{K94} vorschlagen wurde. Ein anderes Verfahren wurde von Horn entwickelt, was die relative Rotation durch Einheitsquaternionen beschreibt \cite{H87}. Im Vergleich zu der Standard-Beschreibung der Rotation als Matrix ist die Quaterniondarstellung viel effizienter und stabiler. Die verbesserte Stabilität kann den Fehler vermeiden, wenn der Winkel der Rotation zur Singularität wird, z.B. $0^\circ$ oder $180^\circ$. D.h. dieses Verfahren braucht keine Maßnahme für Behandlung des speziellen Winkels, was aber im Verfahren von Arun nötig ist \cite{AHB87}. 
\\
\\
Eggert et al. haben in ihrer Arbeit die obengenannte zwei Verfahren mit zwei anderen geschlossene Form-Verfahren verglichen \cite{ELF97}. Wenn die Anzahl der betrachteten Punkten weniger als 100 ist, braucht das Verfahren mit Einheitsquaternionen weniger Zeit als die anderen Verfahren. Auf der anderen Seite, wenn die Anzahl der betrachteten Punkten weniger als 10 ist, liefert das Verfahren von Arun den kleinsten Fehler.

\subsubsection{Iterative Closest Point Algorithmus}
Der Iterative Closest Point Algorithmus ist ein Algorithmus, der es ermöglicht, Punktwolken aneinander anzupassen \cite{IW}. In jedem Iterationsschritt wird der korrespondierende Punkt für jeden Punkt einer Punktwolke aus anderer Punktwolke gefunden. Die Transformation zwischen beiden Punktwolken werden so bestimmt, dass die Summe des Abstands der korrespondierenden Punkte minimiert wird. Dieser Vorgang wird wiederholt, bis die Veränderung des mittleren quadratischen Fehler zwischen zwei folgenden Schritten unter einer Schranke liegt. Der Algorithmus wurde erst von Chen und Medioni \cite{CM91} vorgestellt und ICP wurde als Name des Algorithmus von Besl und McKay in ihrer Arbeit erstmals benutzt \cite{BM92}.  Doria et al. erweiterten den  Algorithmus mit gewichtetem Kriterium für die Behelligung \cite{DMJ97}. Ein schöner Vergleich der verschiedene ICP Algorithmen vor dem Jahr 2001 wurde von Rusinkiewicz und Levoy ausgegeben \cite{RL01}. Der grundlegende ICP Algorithmus wurde von ihnen in 6 Schritten unterteilt. In jedem Schritt wurde die Leistung des Algorithmus verglichen und ihr Einfluss auf den ganzen Algorithmus diskutiert. Eine andere Veränderung wurde von Chavarria und Sommer vorgeschlagen, in der die Kontur des Objekts auch in der Schätzung der Pose betrachtet wird \cite{CS07}.      

\subsection{Objektkalibrierung}
Das Problem der Kalibrierung der Objekte ist ähnlich zum Problem der Segmentierung der Bewegungen in einer langen Bildsequenz. Eine traditionelle Lösungsstrategie ist, die Positionen der Marken im nächsten Zeitpunkt mit Kalman Filter vorherzusagen. Dann werden alle Marken anhand der kinematischen Parameter in verschiedene Gruppen eingeteilt. Mills und Novins haben eine andere Möglichkeit geliefert, damit die Objekte direkt mit 2D Graphen kalibriert werden können \cite{MN00}. Am Anfang ihres Algorithmus wird jede Marke mit einander verbunden. Dann werden alle Marken und die Kanten dazwischen zusammen als ein vollständig Graph dargestellt. Zwischen den Bewegungen der Objekte verändert sich die Länge der Kanten. Die Kanten, die länger als eingesetzte Beschränkung sind, werden aus dem Graphen Schritt um Schritt gelöscht. Eine Marke gehört einem Objekt, genau dann wenn das Dreieck, das von dieser Marke und anderen Marken in diesem Objekt erzeugt wird, mindestens eine gleiche Kante mit den anderen Dreiecken des Objekts hat. Am Ende des Algorithmus wird der ursprüngliche vollständige Graph in viele Teilgraphen zerlegt, die genau den kalibrierten Objekten entsprechen. Es gibt jedoch die Einschränkung in dem Algorithmus von Mills und Novins, dass zwei Objekte nicht auseinanderzuhalten sind, wenn ihre Marken mit einigen besonderen Strukturen angebracht werden \cite{AJ05}. Rhijn und Mulder haben dieses Problem gelöst, indem sie die Voraussetzung des Algorithmus veränderten. In der neuen Voraussetzung darf die Marke in einem Objekt erkannt werden, nur wenn sie mit anderen drei Marken in dem Objekt zusammen eine Pyramide erzeugen kann. Die Pyramide hier bezieht sich auf einen Körper der Geometrie, der vier Knoten hat und jede zwei davon eine Kanten erzeugen. Die neue stärkere Beschränkung erhöht die Erfolgsquote deutlich.

\subsection{Objekterkennung und Verfolgung} 
Das Ziel dieser Arbeit ist, dass ein Objekt nach Initialisierung von dem System wieder erkannt werden kann. Eine Wiedererkennung des 3D Objekts durch 2D Bildfolgen wird von Lamdan et al. in ihrer Arbeit erfolgreich durchgeführt \cite{LSW88}. Sie haben einige interessante Punkte ausgewählt, um das totale Objekt zu beschreiben. Alle drei Punkte, die nicht in gleicher Gerade liegen, definieren ein Koordinatensystem, auf dem die entsprechenden Koordinaten von anderen Punkten berechnet und in einem HashMap gespeichert werden. Die richtige Korrespondenz wird so bestimmt, dass das kleinste Quadrate Modell der Transformation zwischen dem neuen Koordinatensystem und 2D Bild die beste Lösung liefert.
\\
\\ 
Andererseits kann die charakteristische Information jedes Objekts einen einzigen vollständigen Graphen erzeugen. Alle sichtbaren Marken des erkannten Objektes können als ein Teilgraph des vollständigen Graphen definiert werden, wodurch das Problem der Objekterkennung bzw. Objektverfolgung als das Teilgraph Isomorphismus Problem abgeleitet werden kann. Es gibt eine große Menge an Algorithmen um das Problem zu behandeln, da das Isomorphismus Problem nicht nur im Bereich der Bildanalyse, sonder auch im Vergleich der Struktur von chemischen Verbindungen oder in biometrischer Identifikation betrachtet wird. Conte et al. haben eine schöne Zusammenfassung über diese Algorithmen veröffentlicht \cite{C04}. Durch ihre Taxonomie können alle diese Verfahren in zwei Gruppen von genauen bzw. ungenauen Graph Matching Algorithmen unterteilt werden. 
\\
\\
In einem genauen Graph Matching wird die strenge Korrespondenz zwischen zwei Graphen bestimmt. Die Abbildung von einen Graphen zu einem anderen soll bijektiv sein. Ullmann hat ein rekursives Rücksetzverfahren beschrieben, das sehr bekannt ist und bis heute für genaues Matching häufig benutzt wird\cite{U76}. Was von Rhijn und Mulder in ihrer Arbeit für die Objekterkennung implementiert wurde, ist auch ein genaues Graph Matching Verfahren \cite{AJ05}. Sie folgen der Idee von Lamdan, aber verbessern das Verfahren mit einer Beschränkung für die Größe des Teilgraphs, die ausreichend für die Unterscheidung von zwei Objekten ist. Nach der Verbesserung ist der neue Algorithmus viel effizienter und stabiler. Cordella et al. haben einen Algorithmus mit Namen VF2 für das Graph und Teilgraph Isomorphismus Problem in großen Graphen entwickelt \cite{CF04}. In dem Vorgang des Matching haben sie einige Regeln definiert, wodurch die Komplexität des Rechnens stark reduziert wird. Eppstein konzentriert auf das Teilgraph Isomorphismus Problem von planaren Graphen \cite{E99}. Der Graph wird in viele kleine Bäume unterteilt. Auf diesen wird mittels dynamischer Programmierung das Matching in linearer Zeit durchgeführt. 
\\
\\
Das genaue Graph Matching ist manchmal ungeeignet, beispielsweise für nicht komplett fest definierte Graphen, was z.B. bei Rauschen oder instabilen Komponenten vorkommt. Wegen des Unterschieds zwischen dem beobachteten Modell und idealen Modell, soll das Matchingsverfahren tolerant sein. Dadurch kann eine Korrespondenz zwischen zwei Graphen gefunden werden, obwohl es keine strenge Transformation dazwischen gibt. Außerdem benötigt das genaue Graph Matching Verfahren exponentielle Laufzeit im Worst-Case, die durch eine Approximation in ungenauen Matchingsverfahren stark reduziert werden kann. Messmer und Bunke haben ein Fehler-tolerantes Verfahren für Teilgraph Isomorphismus mit unbekanntem Graph als Eingabe entwickelt \cite{MB98}. Die Modellgraphen werden durch eine Vorverarbeitung in kleine Teilgraphen unterteilt. Alle diese Teilgraphen werden so zusammengefasst, dass die oftmals vorkommenden Teilgraphen nur ein mal repräsentiert werden. Der eingegebene Graph wird mit diesen verdichteten Graphen verglichen. Dadurch hängt die Laufzeit nur von der Anzahl der Modellgraphen ab.



